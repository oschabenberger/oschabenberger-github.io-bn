<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Foundations of Data Science - 28&nbsp; Bias and Harm in Algorithms</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../ethics/privacy.html" rel="next">
<link href="../ethics/gonewrong.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ethics/intro.html">Module VII. Applied Ethics in Data Science</a></li><li class="breadcrumb-item"><a href="../ethics/bias_harm.html"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Bias and Harm in Algorithms</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Foundations of Data Science</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Module I. Data Science Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">History and Evolution of Data Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/lifecycle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Data Science Project Lifecycle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/thinkingds.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Thinking Like a Data Scientist</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/teams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Roles on Data Science Teams</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module II. Business Understanding: Discovery</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../busi/bus_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../busi/approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Approach and Methodology</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../busi/examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Example: Email Campaign Optimization</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module III. Data Engineering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/data_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/sources_and_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data Sources and File Formats</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/data_access.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Data Access</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/quality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Data Quality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/summarization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Data Summarization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Data Visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/sqlbasics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">SQL Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/integration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Data Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Module IV. Modeling Data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/model_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/model_concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">General Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Correlation and Causation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/bias_variance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">The Bias-Variance Tradeoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/test_cv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Testing, Validation, Cross-Validation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/featproc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Feature and Target Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">Module V. Evaluation &amp; Communication</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Module VI. Operationalization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../integ/ds_softwareeng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Data Science versus Software Engineering,</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../integ/coding_practices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Coding Best Practices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../integ/tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Data Science Tools</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Module VII. Applied Ethics in Data Science</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/gonewrong.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">How Things Go Wrong</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/bias_harm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Bias and Harm in Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/privacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Personal Information and Personal Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/genAI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Ethics of Generative AI</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Module VIII. Review Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reviewmaterial/mathstat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Probability and Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../reviewmaterial/linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Linear Algebra</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#are-data-biased" id="toc-are-data-biased" class="nav-link active" data-scroll-target="#are-data-biased"><span class="header-section-number">28.1</span> Are Data Biased?</a></li>
  <li><a href="#seven-eight-sources-of-harm" id="toc-seven-eight-sources-of-harm" class="nav-link" data-scroll-target="#seven-eight-sources-of-harm"><span class="header-section-number">28.2</span> Seven (Eight) Sources of Harm</a>
  <ul>
  <li><a href="#historical-bias" id="toc-historical-bias" class="nav-link" data-scroll-target="#historical-bias">Historical Bias</a></li>
  <li><a href="#representation-bias" id="toc-representation-bias" class="nav-link" data-scroll-target="#representation-bias">Representation Bias</a></li>
  <li><a href="#measurement-bias" id="toc-measurement-bias" class="nav-link" data-scroll-target="#measurement-bias">Measurement Bias</a></li>
  <li><a href="#aggregation-bias" id="toc-aggregation-bias" class="nav-link" data-scroll-target="#aggregation-bias">Aggregation Bias</a></li>
  <li><a href="#learning-bias" id="toc-learning-bias" class="nav-link" data-scroll-target="#learning-bias">Learning Bias</a></li>
  <li><a href="#evaluation-bias" id="toc-evaluation-bias" class="nav-link" data-scroll-target="#evaluation-bias">Evaluation Bias</a></li>
  <li><a href="#deployment-bias" id="toc-deployment-bias" class="nav-link" data-scroll-target="#deployment-bias">Deployment Bias</a></li>
  <li><a href="#emergent-bias" id="toc-emergent-bias" class="nav-link" data-scroll-target="#emergent-bias">Emergent Bias</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../ethics/intro.html">Module VII. Applied Ethics in Data Science</a></li><li class="breadcrumb-item"><a href="../ethics/bias_harm.html"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Bias and Harm in Algorithms</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ethics-bias-harm" class="quarto-section-identifier"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Bias and Harm in Algorithms</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="are-data-biased" class="level2" data-number="28.1">
<h2 data-number="28.1" class="anchored" data-anchor-id="are-data-biased"><span class="header-section-number">28.1</span> Are Data Biased?</h2>
<p>The previous section presented examples where things went wrong, where algorithms had unintended consequences and side effects. It is easy to say that the data is biased and thus the fault lies with the data used in training models. The data can be a major source of problems in data analytics. But the answer cannot be as simple as saying “garbage—in—garbage—out”.</p>
<p>Training models on data that are not representative of the situation to which the model will be applied is just one possible form of bias, called representation bias. It can occur even if the data was collected perfectly, measured without error, sampled adequately—for a different purpose than it is now used. This is not unlike our statistical understanding of bias, as the (average) difference between an estimator and its target. A perfectly qualified estimator can be biased for one target and unbiased for another target. The sample mean <span class="math inline">\(\overline{Y}\)</span> of a random sample is an unbiased estimator of the mean <span class="math inline">\(\text{E}[Y] = \mu\)</span> of the sampled population and is a biased estimator of the median of the population unless the distribution of <span class="math inline">\(Y\)</span> is symmetric (mean and median are then identical). Context matters.</p>
<p>Rather than taking a 30,000-foot view that “data are biased” or “data can be biased” and harm of data-dependent models is a possible consequence, it is worthwhile to drill deeper and ask what types of biases exist and how unintended consequences and harm flows from the way in which we build, test, and deploy models. Data can be biased. We need to ask in what way bias can be introduced into data, through data, and through processing data. Without this understanding we cannot apply remedies.</p>
<p>Algorithms are normally not purposefully built to be unfair or cause harm. Instead, they are the result of processes that lead to algorithms that make unfair or harmful decisions. So how does it happen that an algorithm in Austria determines that <a href="https://amsalgorithmus.at/en/">women have lower employability than men</a> if all other characteristics are equal? How is it possible that female job seekers are less likely to see advertisements on Google for high-paying jobs than their male counterparts? We know that the algorithm is unfair because we can test it. That is exactly what researchers from Carnegie Mellon did; they put the advertisement algorithm through the ringer with a designed experiment. As reported by the <a href="https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study">Guardian</a>:</p>
<blockquote class="blockquote">
<p><em>One experiment showed that Google displayed adverts for a career coaching service for “$200k+” executive jobs 1,852 times to the male group and only 318 times to the female group. Another experiment, in July 2014, showed a similar trend but was not statistically significant.</em></p>
</blockquote>
<p>In the excellent paper “A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle”, on which this discussion is partly based, <span class="citation" data-cites="SureshGuttag">Suresh and Guttag (<a href="../references.html#ref-SureshGuttag" role="doc-biblioref">2021</a>)</span> give the following example where the same intervention to correct bias works in one case and fails in another.</p>
<div class="example">
<div class="example-header">
<p>Example: Sample More Women</p>
</div>
<div class="example-container">
<p>The goal is to build a model to predict the risk of a heart attack. A researcher trains a model on medical records from prior patients at a hospital and observes that the false negative rate of the trained model is higher for women than for men. Assuming that the reason for the poorer predictive performance is a lack of data on women in the records, the researcher adds more data on women who suffered heart attacks. The re-trained model shows improved performance in predicting heart attacks in women.</p>
<p>In another application, a hiring model is developed to determine suitability of candidates based on their resume, augmented by candidate ratings supplied by human evaluators. It is observed that the model predicts women to be less likely as suitable candidates compared to men. To correct this shortcoming, more data is collected on women, but the model does not improve. In both scenarios the model builders recognized a deficiency in the model and tried to correct it—that is ethical behavior.</p>
<p>But the same intervention, collecting more data on the group for which the model performed poorly, was successful in one instance and pointless in the other. The reason is that the model deficiency is due to different sources of bias. In the medical example, the training data under-represented women, there was not enough information about women in the data to create a model that was as accurate for that group as it was for the group more heavily represented in the data—men.</p>
<p>Modifying the sampling process changed the distribution of genders in the training data. In the hiring example, the bias is not introduced through the representativeness of the sample, but through the human-assigned rating. When the human assessment of candidate suitability disadvantages women over men, adding more data will not correct the model.</p>
</div>
</div>
</section>
<section id="seven-eight-sources-of-harm" class="level2" data-number="28.2">
<h2 data-number="28.2" class="anchored" data-anchor-id="seven-eight-sources-of-harm"><span class="header-section-number">28.2</span> Seven (Eight) Sources of Harm</h2>
<p><span class="citation" data-cites="SureshGuttag">Suresh and Guttag (<a href="../references.html#ref-SureshGuttag" role="doc-biblioref">2021</a>)</span> describe seven distinct sources of bias and associate them with steps in the modeling cycle, from data preparation to model deployment.</p>
<div id="fig-ethics-seven-sources" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ethics-seven-sources-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/SevenSourcesOfHarm.png" class="lightbox" data-glightbox="description: .lightbox-desc-1" data-gallery="quarto-lightbox-gallery-1"><img src="images/SevenSourcesOfHarm.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ethics-seven-sources-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;28.1: The seven sources of harm in machine learning models <span class="citation" data-cites="SureshGuttag">(<a href="../references.html#ref-SureshGuttag" role="doc-biblioref">Suresh and Guttag 2021</a>)</span>.
</figcaption>
</figure>
</div>
<section id="historical-bias" class="level3">
<h3 class="anchored" data-anchor-id="historical-bias">Historical Bias</h3>
<p>Models do not extrapolate what they learned from the training data to situations that do not reflect the training data. They can create associations only from what is in the training data: the past is prologue.</p>
<p>A system that reflects accurately how the world is or was can inflict harm, either by unfairly withholding resources (allocation harm) or by perpetuating stereotypes (representational harm).</p>
<p>Historical bias, also called pre-existing bias, is rooted in social institutions, practices and attitudes that are reflected in training data. Baking these into the algorithm reinforces and materializes the bias. In the example of the Austrian employability algorithm, the data reflected an accurate representation of a discriminatory labor market, women, especially women with children, are less likely to be found in high-paying jobs. The algorithm trained on this data assigned a lower employability score to women.</p>
<p>If you train a model on data from textbooks, then it is more likely to identify engineers as men than as women, since that profession is historically more likely to be depicted by men. Word embeddings are numerical representations of text data used to train language models. Any stereotypes in the source texts on which the embeddings are based will live on in the models developed based on the embeddings.</p>
<p>The historical bias might not be evident right away. It can rear its ugly side when the model is applied in an unforeseen way. Google Translate got into trouble when documents were translated from Hungarian into English. Hungarian is a gender-neutral language, so the algorithm had to apply pronouns in the English translation. From the <a href="https://www.dailymail.co.uk/news/article-9396937/University-lecturer-slams-sexist-Google-Translate.html">article</a> on DailyMail.com:</p>
<blockquote class="blockquote">
<p><em>‘She’ was placed before domestic chores such as cleaning and sewing, while ‘he’ was used for intellectual pursuits such as being a politician or a professor.</em></p>
</blockquote>
<blockquote class="blockquote">
<p><em>‘He teaches. She cooks. He’s researching. She is raising a child. He plays music. She’s a cleaner. He is a politician. He makes a lot of money. She is baking a cake. He’s a professor. She’s an assistant.’</em></p>
</blockquote>
<p>The researcher who found the issue blamed Google. Google blamed the algorithm on society: the algorithm inadvertently replicated gender biases that exist in the information it scraped from the internet.</p>
<p>How can we fix this type of bias?</p>
<ul>
<li><p><strong>Change the data</strong>. One could revisit the training data in the translation example and change gender pronouns to achieve better balance across attributes. The trained algorithm then would hopefully reflect that balance. Modifying data is considered unethical. There be dragons! What proportion of female pronouns should be used for, say, a profession. The currently prevailing proportion or a desired future state? In Hungary or the U.S? Who decides what that is?</p></li>
<li><p><strong>Use different dat</strong>a. Finding a data source that does not have historical bias baked into it sounds good but might not be possible.</p></li>
<li><p><strong>Adjust the model</strong>. Corrections can be made to the inner workings of the model. For example, instead of using gendered pronouns the translation can use gender-neutral language: “they cook, they teach”. Alternatively, the gender pronouns in the translation can be chosen randomly.</p></li>
</ul>
</section>
<section id="representation-bias" class="level3">
<h3 class="anchored" data-anchor-id="representation-bias">Representation Bias</h3>
<p><strong>Representation bias</strong> bias occurs because of a mismatch between sample, target, and application population. The target population is the universe we have in mind in developing an algorithm. The sample population is the population represented by the training data. The application population is the universe to which the model is applied. It is easy to create mismatches.</p>
<p>A model developed for house values in Boston probably does not apply in Chicago without re-training on data from Chicago. The target population (Boston) and application population (Chicago) are mismatched.</p>
<p><strong>Sampling bias</strong>—also called <strong>selection bias</strong>—is a form of representation bias where the sampling method is defective and does not represent the target population. A random sample is always representative of the target population but there are many ways in which the training data can deviate from the properties of a random sample from the target population:</p>
<ul>
<li><p>Available data can misrepresent the target population, for example, if medical data is only available for individuals having a condition.</p></li>
<li><p>Random sampling that does not reflect the distribution of groups in the target population, for example, drawing random samples from lists of users (website, mobile phone, phone book, tax records) does not accurately represent the overall population (over-/under-coverage).</p></li>
<li><p>Missing values processes that are related to the objective of the study. When recipients in a mental health survey are less likely to respond because of their mental health status, the sample of survey responses is biased (non-response bias).</p></li>
<li><p>Self-selection: participants who exercise control over their inclusion in a study can bias the data. Folks calling into radio shows or participating in online polls are particularly motivated by issues and their responses overestimate strong opinions in the population.</p></li>
<li><p>Survivorship bias can occur when the sample focuses on those meeting a selection criterion. For example, studying current companies does not reflect companies that have previously failed.</p></li>
<li><p>Drop-out: subjects drop out of a long-term study for reasons related to the objective of the study. Losing study participants in a longitudinal health study that move out of the area because of a new job probably does not bias the data. Losing study participants because of deteriorating health might bias the data.</p></li>
</ul>
<div class="example">
<div class="example-header">
<p>Example: Literary Digest Poll</p>
</div>
<div class="example-container">
<p>A famous example of sampling bias because of under-coverage and non-response bias was the 1936 poll by the Literary Digest magazine to predict the outcome of the presidential race between incumbent Democratic candidate Franklin D. Roosevelt and Republican candidate Alf Landon. The magazine sampled voters based on its own subscribers, phonebooks and car registration data and predicted that Alf Landon would win the election.</p>
<p>Instead, Franklin D. Roosevelt defeated Landon in a landslide. Although it had sampled millions of voters, the magazine’s prediction was way off, by more than 19%. The embarrassment contributed to the magazine’s demise by 1938.</p>
<p>Sampling bias due to an inappropriate sampling frame was one factor for the imprecise survey. Subscribers to Literary Digest, phone users and automobile owners were on average wealthier than the average American. Their responses over-estimated the proportion of Republican voters. The second, and primary source of bias was non-response bias: those who disliked Roosevelt were more likely to respond in favor of Landon.</p>
</div>
</div>
<p>In an earlier chapter we mentioned ImageNet, a large database of images used in computer vision challenges and to benchmark object classification algorithms. ImageNet does not represent a random sample of all images that could be taken. Almost half of its images originate in the U.S., only 1—2% of the images come from China and India. A computer vision model trained on ImageNet data is expected to perform worse classifying objects from images from those geographic areas.</p>
<p>This is a special kind of bias. Groups that occur in the data less frequently are predicted with less accuracy, simply because there are fewer training samples in those groups compared to others. In the ImageNet example this is due to the way the data are collected from the internet. If a population is properly sampled randomly, minorities will appear less frequently in the sample than majorities. When model performance is analyzed stratified by groups, the model will be less accurate (have a larger prediction error or mis-classification rate) for groups that contributed fewer observations. Differentiated levels of accuracy are unfair and potentially harmful.</p>
<p>The cause of representation bias might not be immediately obvious, while its presence can be very obvious in the results.</p>
<div class="example">
<div class="example-header">
<p>Example: “Delving” into ChatGPT</p>
</div>
<div class="example-container">
<p>Jeremy Nguyen asked on X (Twitter) why there was such an increase in the recent use of “delve” in medical papers and presented <a href="#fig-delve-pubmed" class="quarto-xref">Figure&nbsp;<span>28.2</span></a> as evidence. The tweet appeared in March 2024, so we still had a long way to go in that year to grow the bar on the right.</p>
<div id="fig-delve-pubmed" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig.align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-delve-pubmed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/DelveMuch.jpeg" class="lightbox" data-glightbox="description: .lightbox-desc-2" data-gallery="quarto-lightbox-gallery-2"><img src="images/DelveMuch.jpeg" class="img-fluid figure-img" style="width:90.0%" data-fig.align="center"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-delve-pubmed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;28.2: Use of “delve” in papers on PubMed. Source:<a href="https://x.com/JeremyNguyenPhD/status/1774021645709295840">JeremyNguyenPhD on X</a>
</figcaption>
</figure>
</div>
<p>Use of “delve” has been on the increase for some time, but in 2023 it took off dramatically. Do medical papers just do more delving since then? It has been noted that ChatGPT responses seem to use certain words more frequently than the internet at large. Examples are “delve”, “explore”, “tapestry”, “testament” and “leverage”. Frequently enough to be seen as a giveaway that text was generated by GPT. GPT 3.5 was released in late 2022 and 2023 is the first full year the world enjoyed ChatGPT. Is <a href="#fig-delve-pubmed" class="quarto-xref">Figure&nbsp;<span>28.2</span></a> evidence that (many) medical papers are now being written—or at least augmented—with the help of ChatGPT?</p>
<p>How is it possible that GPT, which is trained on a massive corpus of text found on the internet, has such an affinity for “delve” and uses it more frequently than would be consistent with the training data? The reason is a special form of representation bias. ChatGPT is a question-answer application built on top of the foundation large-language model GPT. The ChatGPT training uses a form of reinforcement learning, called reinforcement learning with human feedback (RLFH). That is a fancy way of saying that in order to perform reinforcement learning, the algorithm needs a reward function with which to rate competing actions–that is, competing responses to the prompt. Scoring the quality of a textual response is difficult and this is where human evaluators come in. The human evaluation can alter or correct an initial response from the AI to create a response with a higher reward score. When this altered response is fed back into the algorithm, the model will eventually learn to respond to maximize the reward, and respond in a way similar to the human evaluator.</p>
<p>This is the first part of the story. The second part of the story is that human evaluation and feedback in training LLMs is time consuming and costly. That is why tech companies outsource this work to places where anglophonic knowledge workers are cheap. As the Guardian points out in <a href="https://www.theguardian.com/technology/2024/apr/16/techscape-ai-gadgest-humane-ai-pin-chatgpt">this</a> article, “delve” is much more frequent in business English in Nigeria than in the U.S. or the U.K. Outsourcing the task to provide human feedback to Nigeria creates a feedback loop that makes ChatGPT write more African English than its original training data.</p>
</div>
</div>
</section>
<section id="measurement-bias" class="level3">
<h3 class="anchored" data-anchor-id="measurement-bias">Measurement Bias</h3>
<p><strong>Measurement bias</strong>—also called <strong>detection bias</strong> or <strong>information bias</strong>—is due to systematic errors in the process of data collection. Random data measurement errors do not contribute to measurement bias, they cause greater variability in the data. A scale that is not properly calibrated, on the other hand, will give systematically incorrect readings of weight—that is a biased measurement.</p>
<p>Incorrect instruments are a source of this bias and insufficient accuracy or limitations of the instruments. Measuring distance that exceed 10 feet with a 10-foot tape measure causes observations to be <strong>censored</strong>. The true distance is larger than 10 feet, but we do not know the exact value. The accuracy of instruments can vary with its range; being most accurate in the mid-range and less accurate above or below.</p>
<p>Bias in measurements applies to qualitative variables as well, for example, when survey interviewers ask participants to rate their satisfaction for the wrong timeframe.</p>
<p>These sources of measurement bias are obvious. Suresh and Guttag also discuss a type of measurement bias that could be called <strong>proxy bias</strong>. The target variable of interest is often not directly observable. Instead, we use proxies to operationalize the concept of interest. <em>Creditworthiness</em>, for example, is not directly observable, and we use credit scores as the proxy. To model <em>student success</em>, we need to define what we mean by that. The choice of proxy affects the quality of the inference. An oversimplification such as GPA can bias the results because it does not apply to all students, does not capture learning outside of the classroom, does not capture skills not assessed as grades, etc.</p>
<p>While the concept of interest is consistent across groups, e.g., <em>has a disease</em>, the technique for measuring its proxy, <em>the diagnosis</em>, can vary among groups. Regional or cultural differences lead to different interpretations of the same context when annotating images. The same 5-point rating scale is used differently depending on someone’s interpretation of the categories. Does the “best” category mean “best in my experience so far” or “the best one could ever hope for”?</p>
<p>In the COMPAS system for predicting recidivism discussed previously, variables like <em>arrested</em> and <em>re-arrested</em> are proxies for criminality. Measurement bias is introduced when certain communities are policed more intensely than others. If the extent to which a higher number of arrests reflects a higher policing intensity is not accounted for, the analysis will be biased and disadvantage the community where policing is higher.</p>
</section>
<section id="aggregation-bias" class="level3">
<h3 class="anchored" data-anchor-id="aggregation-bias">Aggregation Bias</h3>
<p><strong>Aggregation bias</strong> occurs when data are grouped or aggregated in a way that ignores or obfuscates important subsets of the data. Trends and associations that we see in aggregated data are not necessarily present in the non-aggregated data. Similarly, trends and associations in non-aggregated data can be missed in aggregated data. For example, working with data at an annual level hides seasonal trends. This can be desirable. It can also lead to bad decisions by not accounting for systematic variation at a smaller level.</p>
<p>Confusing the units of inference with the units of analysis is known as an <strong>ecological fallacy</strong>: to assume that what is true for a population is also true for the individual members of the population. One commits an ecological fallacy by concluding that individuals from families in poverty perform less well in school by studying the correlation between average poverty level in schools and school test averages. The analysis is based on aggregates at the school level, an association at that level does not imply an association at the individual level. A proper analysis takes a multi-level approach that models effects at the student, classroom, and school level.</p>
</section>
<section id="learning-bias" class="level3">
<h3 class="anchored" data-anchor-id="learning-bias">Learning Bias</h3>
<p>This type of bias occurs when the process of training the model introduces bias by emphasizing some criteria more than others. For example, classification models are often trained to minimize the mis-classification rate (maximize the accuracy) on a test data set. Models with a high accuracy are not guaranteed to have a high true positive or true negative rate. If it is important to minimize for a low false positive or a low false negative rate, then the learning algorithm should focus on that criterion (probably at the expense of the overall accuracy).</p>
<p>If the purpose of deriving a model is confirmatory inference, then driving the mean-squared prediction error is unlikely to lead to the best model for hypothesis testing.</p>
<p>Techniques that simplify models such as pruning decision trees or compressing neural networks can amplify performance disparities on data with under-represented groups because the models retain the most frequent features.</p>
</section>
<section id="evaluation-bias" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-bias">Evaluation Bias</h3>
<p><strong>Evaluation bias</strong> is related to learning bias in that it is caused by the ways in which we evaluate model performance. The use of benchmark data sets to judge the quality of a model is common in computer vision applications. This becomes problematic if the performance of the model against the benchmark is more important than solving the problem in the first place. In particular, if the benchmark data is not without issues. Training a face recognition algorithm against a benchmark data set that under-represents dark-skinned faces encourages models that do not as well for that group than for light-skinned faces.</p>
<p>Evaluation bias can also occur if we focus model evaluation on individual metrics and compare models on metrics that do not sufficiently differentiate. An example is the use of global goodness-of-fit criteria such as AIC (Akaike’s Information Criterion), BIC (Bayesian Information Criterion). Or Adjusted-<span class="math inline">\(R^2\)</span>. These statistics are frequently used to compare models that are not nested—that is, models that cannot be reduced by applying a hypothesis. An example is comparing a random forest and a regression model. Choosing the “best” model based on a single, overall number is straightforward and dangerous. You might end up with the best of a bunch of bad alternatives.</p>
</section>
<section id="deployment-bias" class="level3">
<h3 class="anchored" data-anchor-id="deployment-bias">Deployment Bias</h3>
<p>This type of bias occurs when the model is used in a way that does not match the problem the model was intended to solve. This can be due to additional decisions that are made in processing the model output.</p>
<p>Suppose a model predicts the employability of an individual on a scale from 0—1. The model fulfills its purpose: to provide an indication of employability based on characteristics of an individual. To operationalize the model in the administration of municipal resources for training and employment support, its predictions are classified into three categories, based on cutoffs between 0 and 1:</p>
<ul>
<li><p>Highly employable individuals <span class="math inline">\(\rightarrow\)</span> they do not need any assistance.</p></li>
<li><p>Medium employable individuals <span class="math inline">\(\rightarrow\)</span> they can receive assistance.</p></li>
<li><p>Poorly employable individuals <span class="math inline">\(\rightarrow\)</span> they cannot receive assistance.</p></li>
</ul>
<p>The cutoffs are likely chosen based on budgetary considerations, what the city can afford. The way in which the model is deployed will withhold resources from those in the “lost cause” category, and probably unfairly so.</p>
<p>The COMPAS recidivism model is another example of deployment bias. Originally intended to predict the risk of predicting a future crime, the scores are used to determine the length of sentences.</p>
</section>
<section id="emergent-bias" class="level3">
<h3 class="anchored" data-anchor-id="emergent-bias">Emergent Bias</h3>
<p>This source of bias is not discussed in the paper by Suresh and Guttag, but plays an increasingly important role in the era of models that continuously learn and adjust, such as AI models.</p>
<p><strong>Emergent bias</strong> does not exist when a data product is first released. It emerges because the product changes (evolves) as users interact with it.</p>
<p>A good example of emergent bias and harm is Microsoft’s Tay chatbot—discussed earlier. It was not a hateful racist when it was first released. Through interaction with users, it was trolled into adopting hateful rhetoric and opinions. Microsoft did not program Tay to be racist, but Microsoft programmed Tay to learn and adapt through interactions.</p>
<p>Emergent bias is also at work when we like things explicitly—hit the “Like” button—or implicitly—post about a topic—on social media. The algorithms analyzing our engagement are more likely to recommend to us similar topics and add those to our social media feed. A bias bubble emerges that over-emphasizes information we are likely to like.</p>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;28.1: The seven sources of harm in machine learning models <span class="citation" data-cites="SureshGuttag">(<a href="../references.html#ref-SureshGuttag" role="doc-biblioref">Suresh and Guttag 2021</a>)</span>.</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;28.2: Use of “delve” in papers on PubMed. Source:<a href="https://x.com/JeremyNguyenPhD/status/1774021645709295840">JeremyNguyenPhD on X</a></span>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-SureshGuttag" class="csl-entry" role="listitem">
Suresh, H., and J. Guttag. 2021. <span>“A Framework for Understanding Sources of Harm Throughout the Machine Learning Life Cycle.”</span> <a href="https://arxiv.org/pdf/1901.10002.pdf">https://arxiv.org/pdf/1901.10002.pdf</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../ethics/gonewrong.html" class="pagination-link" aria-label="How Things Go Wrong">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">How Things Go Wrong</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../ethics/privacy.html" class="pagination-link" aria-label="Personal Information and Personal Data">
        <span class="nav-page-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Personal Information and Personal Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Foundations of Data Science by Oliver Schabenberger</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","selector":".lightbox","loop":false,"openEffect":"zoom","descPosition":"bottom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>