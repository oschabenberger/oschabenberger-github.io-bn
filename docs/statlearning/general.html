<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Foundations of Data Science - 12&nbsp; General Topics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../statlearning/mathstat.html" rel="next">
<link href="../data/integration.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../statlearning/general.html">Part III. Statistical Learning</a></li><li class="breadcrumb-item"><a href="../statlearning/general.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">General Topics</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Foundations of Data Science</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Part I. Data Science and Data Science Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/history.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">History and Evolution of Data Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/lifecycle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Data Science Project Lifecycle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../proj/teams.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Science Teams</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Part II. Data Preparation and Understanding</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/sources_and_files.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Sources and File Formats</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/data_access.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Data Access</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/quality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Quality</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/summarization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Data Summarization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Data Visualization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/sqlbasics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">SQL Basics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../data/integration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Data Integration</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Part III. Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statlearning/general.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">General Topics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statlearning/mathstat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Probability and Statistics</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statlearning/linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Linear Algebra</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statlearning/featproc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Feature and Target Processing</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Part IV. Applied Ethics in Data Science</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/gonewrong.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">How Things Go Wrong</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/bias_harm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Bias and Harm in Algorithms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ethics/privacy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Personal Information and Personal Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Part V. Integration of Data Science Solutions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../integ/coding_practices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Coding Best Practices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../integ/tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Data Science Tools</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">12.1</span> Introduction</a></li>
  <li><a href="#statistical-models" id="toc-statistical-models" class="nav-link" data-scroll-target="#statistical-models"><span class="header-section-number">12.2</span> Statistical Models</a>
  <ul>
  <li><a href="#statistical-learning-and-machine-learning" id="toc-statistical-learning-and-machine-learning" class="nav-link" data-scroll-target="#statistical-learning-and-machine-learning">Statistical Learning and Machine Learning</a></li>
  <li><a href="#stochastic-and-statistical-models" id="toc-stochastic-and-statistical-models" class="nav-link" data-scroll-target="#stochastic-and-statistical-models">Stochastic and Statistical Models</a></li>
  <li><a href="#model-components" id="toc-model-components" class="nav-link" data-scroll-target="#model-components">Model Components</a>
  <ul class="collapse">
  <li><a href="#mean-function" id="toc-mean-function" class="nav-link" data-scroll-target="#mean-function">Mean function</a></li>
  <li><a href="#systematic-component" id="toc-systematic-component" class="nav-link" data-scroll-target="#systematic-component">Systematic component</a></li>
  <li><a href="#random-component" id="toc-random-component" class="nav-link" data-scroll-target="#random-component">Random component</a></li>
  <li><a href="#response-target-variable" id="toc-response-target-variable" class="nav-link" data-scroll-target="#response-target-variable">Response (Target) variable</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#supervised-and-unsupervised-methods" id="toc-supervised-and-unsupervised-methods" class="nav-link" data-scroll-target="#supervised-and-unsupervised-methods"><span class="header-section-number">12.3</span> Supervised and Unsupervised Methods</a>
  <ul>
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised Learning</a></li>
  <li><a href="#unsupervised-learning" id="toc-unsupervised-learning" class="nav-link" data-scroll-target="#unsupervised-learning">Unsupervised Learning</a></li>
  <li><a href="#reinforcement-learning" id="toc-reinforcement-learning" class="nav-link" data-scroll-target="#reinforcement-learning">Reinforcement Learning</a></li>
  </ul></li>
  <li><a href="#regression-and-classification" id="toc-regression-and-classification" class="nav-link" data-scroll-target="#regression-and-classification"><span class="header-section-number">12.4</span> Regression and Classification</a>
  <ul>
  <li><a href="#regression-and-the-regression-to-the-mean-fallacy" id="toc-regression-and-the-regression-to-the-mean-fallacy" class="nav-link" data-scroll-target="#regression-and-the-regression-to-the-mean-fallacy">Regression and the Regression to the Mean Fallacy</a></li>
  <li><a href="#regression-models" id="toc-regression-models" class="nav-link" data-scroll-target="#regression-models">Regression Models</a></li>
  <li><a href="#classification-problems" id="toc-classification-problems" class="nav-link" data-scroll-target="#classification-problems">Classification Problems</a>
  <ul class="collapse">
  <li><a href="#misclassification-rate" id="toc-misclassification-rate" class="nav-link" data-scroll-target="#misclassification-rate">Misclassification rate</a></li>
  <li><a href="#from-probabilities-to-classification" id="toc-from-probabilities-to-classification" class="nav-link" data-scroll-target="#from-probabilities-to-classification">From probabilities to classification</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#prediction-and-explanation" id="toc-prediction-and-explanation" class="nav-link" data-scroll-target="#prediction-and-explanation"><span class="header-section-number">12.5</span> Prediction and Explanation</a></li>
  <li><a href="#correlation-and-causation" id="toc-correlation-and-causation" class="nav-link" data-scroll-target="#correlation-and-causation"><span class="header-section-number">12.6</span> Correlation and Causation</a>
  <ul>
  <li><a href="#correlation" id="toc-correlation" class="nav-link" data-scroll-target="#correlation">Correlation</a></li>
  <li><a href="#spurious-correlation" id="toc-spurious-correlation" class="nav-link" data-scroll-target="#spurious-correlation">Spurious Correlation</a></li>
  <li><a href="#experimentation" id="toc-experimentation" class="nav-link" data-scroll-target="#experimentation">Experimentation</a></li>
  <li><a href="#the-ladder-of-causation" id="toc-the-ladder-of-causation" class="nav-link" data-scroll-target="#the-ladder-of-causation">The Ladder of Causation</a>
  <ul class="collapse">
  <li><a href="#first-rungseeing" id="toc-first-rungseeing" class="nav-link" data-scroll-target="#first-rungseeing">First rung—seeing</a></li>
  <li><a href="#second-rungdoing" id="toc-second-rungdoing" class="nav-link" data-scroll-target="#second-rungdoing">Second rung—doing</a></li>
  <li><a href="#third-rungimagining" id="toc-third-rungimagining" class="nav-link" data-scroll-target="#third-rungimagining">Third rung—imagining</a></li>
  <li><a href="#the-role-of-data" id="toc-the-role-of-data" class="nav-link" data-scroll-target="#the-role-of-data">The role of data</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#bias-variance-tradeoff" id="toc-bias-variance-tradeoff" class="nav-link" data-scroll-target="#bias-variance-tradeoff"><span class="header-section-number">12.7</span> Bias-Variance Tradeoff</a>
  <ul>
  <li><a href="#a-simulation" id="toc-a-simulation" class="nav-link" data-scroll-target="#a-simulation">A Simulation</a></li>
  <li><a href="#accuracy-and-precision" id="toc-accuracy-and-precision" class="nav-link" data-scroll-target="#accuracy-and-precision">Accuracy and Precision</a></li>
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error">Mean Squared Error</a></li>
  <li><a href="#overfitting-and-underfitting" id="toc-overfitting-and-underfitting" class="nav-link" data-scroll-target="#overfitting-and-underfitting">Overfitting and Underfitting</a></li>
  </ul></li>
  <li><a href="#training-testing-and-validation" id="toc-training-testing-and-validation" class="nav-link" data-scroll-target="#training-testing-and-validation"><span class="header-section-number">12.8</span> Training, Testing, and Validation</a>
  <ul>
  <li><a href="#training-data" id="toc-training-data" class="nav-link" data-scroll-target="#training-data">Training Data</a></li>
  <li><a href="#test-data" id="toc-test-data" class="nav-link" data-scroll-target="#test-data">Test Data</a></li>
  <li><a href="#validation-data" id="toc-validation-data" class="nav-link" data-scroll-target="#validation-data">Validation Data</a></li>
  <li><a href="#hold-out-sample" id="toc-hold-out-sample" class="nav-link" data-scroll-target="#hold-out-sample">Hold-out Sample</a></li>
  </ul></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><span class="header-section-number">12.9</span> Cross-validation</a>
  <ul>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">Loss Functions</a></li>
  <li><a href="#k-fold-cross-validation" id="toc-k-fold-cross-validation" class="nav-link" data-scroll-target="#k-fold-cross-validation"><span class="math inline">\(K\)</span>-fold Cross-validation</a></li>
  <li><a href="#leave-one-out-cross-validation" id="toc-leave-one-out-cross-validation" class="nav-link" data-scroll-target="#leave-one-out-cross-validation">Leave-One-Out Cross-validation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../statlearning/general.html">Part III. Statistical Learning</a></li><li class="breadcrumb-item"><a href="../statlearning/general.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">General Topics</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-statlearn-general" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">General Topics</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">12.1</span> Introduction</h2>
<p>This chapter dives into selected topics to set the stage for a more rigorous mathematical treatment later. The goal is to understand the concepts and to become familiar with the notation and terminology of data analytics. The material depends more on formulas than previous chapter but is not very “mathy”.</p>
<p>At the end of the chapter you will know about important classes of statistical models and how to express them mathematically. The difference between regression and classification models will be clear and how regression predictions are often the precursor to classifications. The bias-variance tradeoff is a balance every data science project needs to strike—you need to understand the origin of the tradeoff and how to measure model performance to find the balance between overfitting and underfitting. Training, test, and validation data sets are universal in data science to help build good models. We cover the basics in this chapter and the details of data splitting and cross-validation later.</p>
</section>
<section id="statistical-models" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="statistical-models"><span class="header-section-number">12.2</span> Statistical Models</h2>
<section id="statistical-learning-and-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="statistical-learning-and-machine-learning">Statistical Learning and Machine Learning</h3>
<p>Much is being made of the difference between statistical models and machine learning models, or to be more precise, between statistical learning (SL) and machine learning (ML).</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Statistical Learning</p>
</div>
<div class="definition-container">
<p><strong>Statistical Learning</strong> is the process of understanding data through the application of tools that describe structure and relationships in data. Models are formulated based on the structure of data to predict outcomes from inputs, to test hypothesis about relationships, to group data, or to reduce the dimensionality of a problem.</p>
</div>
</div>
<p>Statistical learning emphasizes prediction more than the testing of hypothesis, as compared to statistical modeling. Many model classes used in statistical learning are the same models one uses to test hypothesis about patterns and relationships in data. Emphasis of prediction over hypothesis testing—or vice versa—flows from the nature of the problem we are trying to solve. The same model can be developed with focus on predictive capability or with focus on interpretability. We do not want to overdo the distinction between statistical learning and statistical modeling: statistical learning uses statistical models.</p>
<p>Learning is the process of converting experience into knowledge and machine learning is an automated way of learning by using computers. Rather than directly programming computers to perform a task, machine learning is used when the tasks are not easily described and communicated (e.g., driving, reading, image recognition) or when the tasks exceed human capabilities (e.g., analyzing large and complex data sets). Modern machine learning discovered data as a resource for learning and that is where statistical learning and machine learning meet.</p>
<p>SL and ML have more in common, than what separates them:</p>
<ul>
<li><p>The input to a learning algorithm is data; the raw material is the same.</p></li>
<li><p>The data are thought of as randomly generated, there is some sense of variability in the data that is attributed to random sources.</p></li>
<li><p>Both disciplines distinguish supervised and unsupervised forms of learning</p></li>
<li><p>They use many of the same models and algorithms for regression, classification, clustering, dimension reduction, etc.</p></li>
</ul>
<p>Machine learning uses observed data to describe relationships and “causes”; the emphasis is on predicting new and/or future outcomes. There is comparatively little emphasis on experimentation and hypothesis testing.</p>
<p>A key difference between SL and ML is what Breiman describes as the difference between data modeling and algorithmic modeling. The difference aligns closely with statistical and machine learning thinking. In data modeling, theory focuses on the probabilistic properties of the model and of quantities derived from it. In algorithmic modeling, the focus is on the properties of the algorithm itself: starting values, optimization, convergence behavior, parallelization, hyperparameter tuning, and so on. Consequently, statisticians are concerned with the asymptotic distributional behavior of estimators and methods as <span class="math inline">\(n \rightarrow \infty\)</span>. Machine learning focuses on finite sample properties and ask what accuracy can be expected based on the available data.</p>
<p>The strong assumptions statisticians make about the stochastic data-generating mechanism that produced the data set in hand as a realization are not found in machine learning. That does not mean that machine learning models are free of stochastic elements and assumptions—quite the contrary. It means that statisticians use the data-generating mechanism as the foundation for conclusions rather than the data alone.</p>
<p>When you look at a <em>p</em>-value in a table of parameter estimates, you rely on all assumptions about distributional properties of the data, correctness of the model, and (asymptotic) distributional behavior of the estimator. They flow explicitly from the data-generating mechanism or implicitly from somewhere else. Otherwise, the <em>p</em>-value does not make much sense. (Many argue that <em>p</em>-values are not very helpful and possibly even damaging to decision making but this is not the origin of this discussion.)</p>
<p>If you express the relationship between a target variable <span class="math inline">\(Y\)</span> and inputs <span class="math inline">\(x_1, \cdots, x_p\)</span> as</p>
<p><span class="math display">\[
Y = f(x_1,\cdots,x_p) + \epsilon
\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> is a random variable, it does not matter whether you perform data modeling or algorithmic modeling. We need to think about <span class="math inline">\(\epsilon\)</span> and its properties. How does <span class="math inline">\(\epsilon\)</span> affect the algorithm, the prediction accuracy, the uncertainty of statements about <span class="math inline">\(Y\)</span> or <span class="math inline">\(f(x_1, \cdots, x_p)\)</span>? That is why all data professionals need to understand about stochastic models and statistical models.</p>
</section>
<section id="stochastic-and-statistical-models" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-and-statistical-models">Stochastic and Statistical Models</h3>
<p>A <strong>stochastic</strong> model describes the probability distribution of outcomes by allowing one or more of the model elements to be random variables.</p>
<p>Suppose we are charged with developing a model to predict recurrence of cancer. There are many possible aspects that influence the outcome:</p>
<ul>
<li>Age, gender</li>
<li>Medical history</li>
<li>Lifestyle factors (nutrition, exercise, smoking, …)</li>
<li>Type of cancer</li>
<li>Size of the largest tumor</li>
<li>Site of cancer</li>
<li>Time since diagnostic, time from treatment</li>
<li>Type of treatment</li>
<li>and so on</li>
</ul>
<p>If we were to try and build a deterministic model that predicts cancer recurrence perfectly, all influences would have to be taken into account and their impact on the outcome would have to be incorporated correctly. That would be an incredibly complex model, and impractical.</p>
<p>By taking a stochastic approach we acknowledge that there are processes that affect the variability in cancer recurrence we observe from patient to patient. The modeling can now focus on the most important factors and how they drive cancer recurrence. The other factors are included through random effects. If the model captures the salient factors and their impact correctly, and the variability contributed by other factors is not too large, and not systematic, the model is very useful. It possibly is much more useful than an inscrutably complex model that tries to accommodate all influences perfectly.</p>
<p>The simplest stochastic model for cancer recurrence is to assume that the outcome is a Bernoulli (binary) random variable taking on two states (cancer recurs, cancer does not recur) with probabilities <span class="math inline">\(\pi\)</span> and <span class="math inline">\(1-\pi\)</span>. If we code the two states numerically, cancer recurs as 1, cancer does not recur as 0, the probability mass function of cancer recurrence is that of the random variable <span class="math inline">\(Y\)</span>,</p>
<p><span class="math display">\[
\Pr(Y=y) = \left \{ \begin{array}{cl} \pi &amp; y=1 \\ 1-\pi &amp; y = 0\end{array} \right .
\]</span></p>
<div class="definition">
<div class="definition-header">
<p>Definition: Statistical Model</p>
</div>
<div class="definition-container">
<p>A <strong>statistical model</strong> is a stochastic model that contains unknown constants, called parameters. Parameters are estimated based on data. Parameters are constants, not random variables. The estimator of a parameter that depends on data is a random variable since the data are random.</p>
</div>
</div>
<p>The parameter in our cancer model is <span class="math inline">\(\pi\)</span>, the probability that <span class="math inline">\(Y\)</span> takes on the value 1. In statistics, this probability is often called the “success” probability and its complement is called the “failure” probability. We prefer to call them the “event” and “non-event” probabilities instead. The event is the binary outcome coded as a 1.</p>
<p>Because we cannot visit with all cancer patients, a sample of patients is used to estimate <span class="math inline">\(\pi\)</span>. This process introduces uncertainty into the estimator of <span class="math inline">\(\pi\)</span>, a larger sample will lead to a more precise (a less uncertain) estimator.</p>
<p>The model is overly simplistic in that it captures all possible effects on cancer recurrence in the single quantity <span class="math inline">\(\pi\)</span>. Regardless of age, gender, type of cancer, etc., we would predict a randomly chosen cancer patient’s likelihood to experience a recurrence as <span class="math inline">\(\pi\)</span>. To incorporate input variables that affect the rate of recurrence we need to add structure to <span class="math inline">\(\pi\)</span>. A common approach in statistical learning and in machine learning is that inputs have a linear effect on a transformation of the probability <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[
g(\pi) = \beta_0 + \beta_1 x_1+\cdots + \beta_p x_p
\]</span></p>
<p>When <span class="math inline">\(g(\pi)\)</span> is the logit function</p>
<p><span class="math display">\[\log\left \{ \frac{\pi}{1-\pi} \right\}\]</span></p>
<p>this is called a <strong>logistic</strong> regression model. <span class="math inline">\(x_1,\cdots,x_p\)</span> are the inputs of the model, <span class="math inline">\(\beta_0, \cdots, \beta_p\)</span> are the parameters of the model. If we accept that the basic structure of the logistic model applies to the problem of predicting cancer occurrence, we use our sample of patient data to</p>
<ul>
<li>estimate the parameters <span class="math inline">\(\beta_0, \cdots, \beta_p\)</span>;</li>
<li>determine which inputs and how many inputs are adequate: we need to determine <span class="math inline">\(p\)</span> and the specific input variables;</li>
<li>determine whether the logit function is the appropriate transformation to linearity.</li>
</ul>
<p>The effect of the inputs is called linear on <span class="math inline">\(g(\pi)\)</span> if <span class="math inline">\(g(\pi)\)</span> is a linear function of the parameters. To test whether this is the case take derivatives of the function with respect to all parameters. If the derivatives do not depend on parameters, the effect is linear.</p>
<p><span class="math display">\[\frac{\partial g(\pi)}{\partial\beta_{0}} = 1\]</span></p>
<p><span class="math display">\[\frac{\partial g(\pi)}{\partial\beta_{1}} = x_{1}\]</span></p>
<p><span class="math display">\[\frac{\partial g(\pi)}{\partial\beta_{p}} = x_{p}\]</span> None of the derivatives depends on any of the <span class="math inline">\((\beta_{0},\ldots,\beta_{p})\)</span>; <span class="math inline">\(g(\pi)\)</span> is linear in the parameters. A non-linear function is non-linear in at least one parameter.</p>
<div class="example">
<div class="example-header">
<p>Example: Plateau (hockey stick) Model</p>
</div>
<div class="example-container">
<p>A plateau model reaches a certain amount of output and remains flat afterwards. When the model prior to the plateau is a simple linear model, the plateau model is also called a hockey-stick model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/PlateauModel.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></p>
</figure>
</div>
<p>The point at which the plateau is reached is called a change point. Suppose the change point is denoted <span class="math inline">\(\alpha\)</span>. The hockey-stick model can be written as</p>
<p><span class="math display">\[
\text{E}\lbrack Y\rbrack = \left\{
\begin{matrix}
\beta_{0} + \beta_{1}x      &amp; x \leq \alpha \\
\beta_{0} + \beta_{1}\alpha &amp; x &gt; \alpha
\end{matrix} \right.
\]</span></p>
<p>If <span class="math inline">\(\alpha\)</span> is an unknown parameters that is estimated from the data, this is a non-linear model.</p>
</div>
</div>
</section>
<section id="model-components" class="level3">
<h3 class="anchored" data-anchor-id="model-components">Model Components</h3>
<p>The expression for the logistic regression model</p>
<p><span class="math display">\[g(\pi) = \beta_{0} + \beta_{1}x_{1} + \ldots + \beta_{p}x_{p}\]</span></p>
<p>looks quite different from the model introduced earlier,</p>
<p><span class="math display">\[Y = f\left( x_{1},\ldots,x_{p} \right) + \epsilon\]</span></p>
<p>Where is the connection?</p>
<p>The error term <span class="math inline">\(\epsilon\)</span> is a random variable and we need to specify some of its distributional properties to make progress. At a minimum we provide the mean and variance of <span class="math inline">\(\epsilon\)</span>. If the model is correct—correct on average—then the error terms should have a mean of zero and not depend on any input variables (whether those in the model or other inputs). A common assumption is that the variance of the errors is a constant and not a function of other effects (fixed or random). The two assumptions are summarized as <span class="math inline">\(\epsilon \sim \left( 0,\sigma^{2} \right)\)</span>; read as <span class="math inline">\(\epsilon\)</span> follows a distribution with mean 0 and variance <span class="math inline">\(\sigma^{2}\)</span>.</p>
<section id="mean-function" class="level4">
<h4 class="anchored" data-anchor-id="mean-function">Mean function</h4>
<p>Now we can take the expected value of the model and find that</p>
<p><span class="math display">\[
\text{E}\lbrack Y\rbrack = \text{E}\left\lbrack f\left( x_{1},\ldots,x_{p} \right) + \epsilon \right\rbrack = f\left( x_{1},\ldots,x_{p} \right) + \text{E}\lbrack\epsilon\rbrack = f\left( x_{1},\ldots,x_{p} \right)
\]</span></p>
<p>Because the errors have zero mean <strong>and</strong> because the function <span class="math inline">\(f\left( x_{1},\ldots,x_{p} \right)\)</span> does not contain random variables, <span class="math inline">\(f\left( x_{1},\ldots,x_{p} \right)\)</span> is the expected value (mean) of <span class="math inline">\(Y\)</span>. <span class="math inline">\(f\left( x_{1},\ldots,x_{p} \right)\)</span> is thus called <strong>mean function</strong> of the model.</p>
<div class="example">
<div class="example-header">
<p>Example: Curvilinear models</p>
</div>
<div class="example-container">
<p>Polynomial models such as a quadratic model <span class="math display">\[Y = \beta_{0} + \beta_{1}x + \beta_{2}x^{2} + \epsilon\]</span> or cubic model <span class="math display">\[Y = \beta_{0} + \beta_{1}x + \beta_{2}x^{2} + \beta_{3}x^{3} + \epsilon\]</span> have a curved appearance when <span class="math inline">\(Y\)</span> is plotted against <span class="math inline">\(x\)</span>. They are linear models, however.</p>
<p>To test this, take derivatives of the mean function with respect to the parameters. For the quadratic model the partial derivatives with respect to <span class="math inline">\(\beta_{0}\)</span>, <span class="math inline">\(\beta_{1}\)</span>, and <span class="math inline">\(\beta_{2}\)</span> are 1, <span class="math inline">\(x\)</span>, and <span class="math inline">\(x^{2}\)</span>, respectively. The model is linear in the parameters.</p>
<p>To emphasize that the models are not just straight lines in <span class="math inline">\(x\)</span>, a linear model with curved appearance is called curvilinear.</p>
</div>
</div>
<p>What does the mean function look like in the logistic regression model? The underlying random variable <span class="math inline">\(Y\)</span> has a Bernoulli distribution. Its mean is</p>
<p><span class="math display">\[\text{E}\lbrack Y\rbrack = \sum y\, \Pr(Y = y) = 1 \times \pi + 0 \times (1 - \pi) = \pi\]</span></p>
<p>The logit function <span class="math display">\[g(\pi) = \log \left\{ \frac{\pi}{(1 - \pi)} \right\}\]</span> is invertible and the model <span class="math display">\[g(\pi) = \beta_0 + \beta_1 x_{1} + \ldots + \beta_p x_p\]</span></p>
<p>can be written as</p>
<p><span class="math display">\[\text{E}\lbrack Y\rbrack = \pi = g^{- 1}\left( \beta_{0} + \beta_{1}x_{1} + \ldots + \beta_{p}x_{p} \right)\]</span></p>
<p>The mean function of the logistic model is also a function of the inputs. It is a neat exercise to show that if <span class="math inline">\(g(\pi)\)</span> is the logit function the mean function is</p>
<p><span class="math display">\[\pi = \frac{1}{1 + \exp\left\{ - \beta_0 - \beta_1 x_1 - \cdots - \beta_p x_p \right\}}\]</span></p>
<p>You can now also show that although <span class="math inline">\(g(\pi)\)</span> is linear in the parameters, <span class="math inline">\(\pi\)</span> is a non-linear function of the parameters.</p>
</section>
<section id="systematic-component" class="level4">
<h4 class="anchored" data-anchor-id="systematic-component">Systematic component</h4>
<p>The mean functions <span class="math display">\[f\left( x_{1},\ldots,x_{p} \right)\]</span> and <span class="math display">\[\frac{1}{1 + \exp\left\{ - \beta_{0} - \beta_{1}x_{1} - \ldots - \beta_p x_p \right\} }\]</span> look rather different, except for the input variables <span class="math inline">\(x_{1},\ldots,x_{p}\)</span>.</p>
<p>For the model <span class="math inline">\(Y = f\left( x_{1},\ldots,x_{p} \right) + \epsilon\)</span> we left it open how the mean function depends on parameters. There are three general approaches.</p>
<p>The systematic component has the form of a <strong>linear predictor</strong>, that is, a linear combination of the inputs. The linear predictor is frequently denoted as <span class="math inline">\(\eta\)</span>:</p>
<p><span class="math display">\[\eta = \beta_{0} + \beta_1 x_1 + \cdots + \beta_p x_p\]</span></p>
<p>The parameter <span class="math inline">\(\beta_0\)</span> is called the <strong>intercept</strong> of the linear predictor. Although optional, it is included in most models to capture the effect on the mean if no input variables are present. Models with a linear predictor and an intercept have <span class="math inline">\(p + 1\)</span> parameters in the mean function.</p>
<p>The logistic regression model also contains a linear predictor. Depending on whether you write the model in terms of <span class="math inline">\(\pi\)</span> or <span class="math inline">\(g(\pi)\)</span>, the expressions are</p>
<p><span class="math display">\[g(\pi) = \eta\]</span></p>
<p><span class="math display">\[\pi = \frac{1}{1 + \exp\{ - \eta \}}\]</span></p>
<p>The mean function can be a <strong>general non-linear</strong> function of the parameters. The number of input variables and the number of parameters can be quite different.</p>
<p>The Mitscherlich model is popular in agricultural studies of plant growth as a function of an input such as a fertilizer. The plant species is a commercial crop. If <span class="math inline">\(Y\)</span> denotes plant yield and <span class="math inline">\(x\)</span> the amount of input, the Mitscherlich model is</p>
<p><span class="math display">\[Y = f(x,\xi,\lambda,\kappa) + \epsilon = \lambda + (\xi - \lambda)\exp\left\{ - \kappa x \right\} + \epsilon\]</span></p>
<p>The mean function <span class="math inline">\(f\)</span>() depends on one input variable <span class="math inline">\(x\)</span> and three parameters <span class="math inline">\((\xi,\lambda,\kappa)\)</span>. Taking derivatives, it is easily established that the mean function is non-linear:</p>
<p><span class="math display">\[\frac{\partial f(x,\xi,\lambda,\kappa)}{\partial\xi} = \exp\{ - \kappa x \}\]</span></p>
<p>The derivative with respect to <span class="math inline">\(\xi\)</span> depends on the <span class="math inline">\(\kappa\)</span> parameter.</p>
<p>Non-linear models like the Mitscherlich equation are appealing because they are easily interpretable. The parameters have meaning in terms of the subject domain:</p>
<ul>
<li><p><span class="math inline">\(\xi\)</span> is the crop yield if no fertilizer is applied, the mean of <span class="math inline">\(Y\)</span> at <span class="math inline">\(x = 0\)</span>. This is the baseline yield</p></li>
<li><p><span class="math inline">\(\lambda\)</span> is the upper yield asymptote as <span class="math inline">\(x\)</span> increases</p></li>
<li><p><span class="math inline">\(\kappa\)</span> relates to a rate of change, how quickly the yield increases from <span class="math inline">\(\xi\)</span> and reaches <span class="math inline">\(\kappa\)</span>.</p></li>
</ul>
<p><a href="#fig-sl-mitscherlich" class="quarto-xref">Figure&nbsp;<span>12.1</span></a> shows the Mitscherlich model fitted to a set of plant yield data, the input variable is the nitrogen rate applied (in kg/ha). Visual estimates for the baseline yield and the asymptotic yield are <span class="math inline">\(\widehat{\xi} = 40\)</span> and <span class="math inline">\(\widehat{\lambda} = 80\)</span>.</p>
<div id="fig-sl-mitscherlich" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-mitscherlich-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Mitscherlich.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" data-glightbox="description: .lightbox-desc-1"><img src="images/Mitscherlich.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-mitscherlich-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.1: Mitscherlich yield equation for plant yield as a function of nitrogen rate fitted to a set of data.
</figcaption>
</figure>
</div>
<p>Interpretability of the parameters enables mapping of research questions to the model:</p>
<ul>
<li><p>Is the asymptotic yield greater than 75? This can be answered with a confidence interval for the estimate of <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>At what level of <span class="math inline">\(x\)</span> does yield achieve 75% of the maximum? This is an inverse prediction problem. Set yield to 75% of <span class="math inline">\(\lambda\)</span> and solve the model for <span class="math inline">\(x\)</span>.</p></li>
<li><p>The rate of change in yield is less than ½ unit once <span class="math inline">\(x = 100\)</span> are applied. This can be answered with a hypothesis test for <span class="math inline">\(\kappa\)</span>.</p></li>
</ul>
<p>The third method of specifying the systematic component is to not write it as a function of inputs and parameters. This is common for non-parametric methods such as smoothing splines, local regression, generalized additive models, and kernel methods. These models still have parameters, but the relationship between inputs and parameters is implied through the method of training the models.</p>
<p>For example, LOESS is a local polynomial regression method. A LOESS model of degree 2 fits a quadratic polynomial model to a portion of the data (a window). Within window <span class="math inline">\(k\)</span>, the model takes the form</p>
<p><span class="math display">\[Y = \beta_{0k} + \beta_{1k}x + \beta_{2k}x^{2} + \epsilon\]</span></p>
<p>As the window moves across the range of <span class="math inline">\(x\)</span>, different observations are captured in the window. The underlying model in each window is a quadratic polynomial but the values of the parameter estimates change from window to window.</p>
</section>
<section id="random-component" class="level4">
<h4 class="anchored" data-anchor-id="random-component">Random component</h4>
<p>The random components of a statistical model are the stochastic elements that describe the distribution of the target variable <span class="math inline">\(Y\)</span>. By now we are convinced that most data we work with are to some degree the result of random processes and that incorporating randomness into models makes sense. The model does not need to be correct for every observation, but it needs to be correct on average—an additive zero-mean random error is OK. Even if all influences on the output <span class="math inline">\(Y\)</span> were known, it might be impossible to measure them, or to include them correctly into the model. Randomness is often introduced deliberately by sampling observations from a population or by randomly assigning treatments to experimental units. Finally, stochastic models are often simpler and easier to explain than other models. Among competing explanations, the simpler one wins (Occam’s Razor).</p>
<p>We have seen two basic ways to reflect randomness in a statistical model:</p>
<ul>
<li><p>By adding an additive error term to a mean function</p></li>
<li><p>By describing the distribution of the target variable</p></li>
</ul>
<p>The Mitscherlich model is an example of the first type of specification:</p>
<p><span class="math display">\[Y = f(x,\xi,\lambda,\kappa) + \epsilon = \lambda + (\xi - \lambda)\exp\left\{ - \kappa x \right\} + \epsilon\]</span></p>
<p>Under the assumption that <span class="math inline">\(\epsilon \sim \left( 0,\sigma^{2} \right)\)</span>, it follows that <span class="math inline">\(Y\)</span> is randomly distributed with mean <span class="math inline">\(f(x,\xi,\lambda,\kappa)\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>; <span class="math inline">\(Y \sim \left( f(x,\xi,\lambda,\kappa),\sigma^{2} \right)\)</span>. If the model errors were normally distributed, <span class="math inline">\(\epsilon \sim N\left( 0,\sigma^{2} \right)\)</span>, then <span class="math inline">\(Y\)</span> would also be normally distributed. Randomness is contagious.</p>
<p>The logistic regression model is an example of the second type of specification:</p>
<p><span class="math display">\[g\left( \text{E}\lbrack Y\rbrack \right) = \beta_{0} + \beta_{1}x_{1} + \ldots + \beta_{p}x_{p}\]</span></p>
<p>and <span class="math inline">\(Y\)</span> follows a Bernoulli distribution. It does not make sense to write the model with an additive error term unless the target variable is continuous.</p>
<p>Models can have more than one random element. In the cancer recurrence example, suppose we want to explicitly associate a random effect with each patient, <span class="math inline">\(b_{i} \sim \left( 0,\sigma_{b}^{2} \right)\)</span>, say. The modified model is now</p>
<p><span class="math display">\[g\left( \pi\ |\ b_{i} \right) = \beta_{0} + b_{i} + \ \beta_{1}x_{1} + \ldots + \beta_{p}x_{p}\]</span></p>
<p>Conditional on the patient-specific value of <span class="math inline">\(b_{i}\)</span> the model is still a logistic model with intercept <span class="math inline">\(\beta_{0} + b_{i}\)</span>. Because the parameters <span class="math inline">\(\beta_{0},\ \cdots,\beta_{p}\)</span> are constants (not random variables), they are also referred to as <strong>fixed effects</strong>. Models that contain both random and fixed effects are called <strong>mixed models</strong>.</p>
<p>Mixed models occur naturally when the sampling process is hierarchical.</p>
<p>For example, you select apples on trees in an orchard to study the growth of apples over time. You select at random 10 trees in the orchard and chose 25 apples at random on each tree. The apple diameters are then measured in two-week intervals. To represent this data structure, we need a few subscripts.</p>
<p>Let <span class="math inline">\(Y_{ijk}\)</span> denote the apple diameter at the <span class="math inline">\(k\)</span><sup>th</sup> measurement of the <span class="math inline">\(j\)</span><sup>th</sup> apple from the <span class="math inline">\(i\)</span><sup>th</sup> tree. A possible decomposition of the variability of the <span class="math inline">\(Y_{ijk}\)</span> could be</p>
<p><span class="math inline">\(Y_{ijk} = \beta_{0} + a_{i} + \eta_{ijk} + \epsilon_{ijk}\)</span></p>
<p>where <span class="math inline">\(\beta_{0}\)</span> is an overall (fixed) intercept, <span class="math inline">\(a_{i} \sim \left( 0,\sigma_{a}^{2} \right)\)</span> is a random tree effect, <span class="math inline">\(\eta_{ijk}\)</span> is an effect specific to apple and measurement time, and <span class="math inline">\(\epsilon_{ijk} \sim \left( 0,\sigma_{\epsilon}^{2} \right)\)</span> are the model errors. This is a mixed model because we have multiple random effects (<span class="math inline">\(a_{i}\)</span> and <span class="math inline">\(\epsilon_{ijk}\)</span>). In addition, we need to decide how to parameterize <span class="math inline">\(\eta_{ijk}\)</span>. Suppose that a simple linear regression trend is reasonable for each apple over time. Estimating a separate slope and intercept for each of the 10 x 25 apples would result in a model with over 500 parameters. A more parsimonious parameterization is to assume that the apples share a tree-specific (fixed) intercept and slope and to model the apple-specific deviations from the tree-specific trends with random variables:</p>
<p><span class="math display">\[\eta_{ijk} = \left( \beta_{0i} + b_{0ij} \right) + {(\beta}_{1i} + b_{1ij})t_{ijk}\]</span></p>
<p><span class="math inline">\(t_{ijk}\)</span> is the time that a given apple on a tree is measured. The apple-specific intercept offsets from the tree-specific intercepts <span class="math inline">\(\beta_{0i}\)</span> are model as random variables <span class="math inline">\(b_{0ij} \sim \left( 0,\sigma_{b_{0}}^{2} \right)\)</span>. Similarly, <span class="math inline">\(b_{1ij} \sim \left( 0,\sigma_{b_{1}}^{2} \right)\)</span> models the apple-specific offset for the slopes as random variables. Putting everything together we obtain</p>
<p><span class="math inline">\(Y_{ijk} = \beta_{0} + \left( \beta_{0i} + b_{0ij} \right) + {(\beta}_{1i} + b_{1ij})t_{ijk} + \epsilon_{ijk}\)</span></p>
<p>Note that <span class="math inline">\(a_{i}\)</span> was no longer necessary in this model, that role is now played by <span class="math inline">\(\beta_{0i}\)</span>.</p>
<p>The total number of parameters in this model is 24 (1 overall intercept, 10 tree-specific intercepts, 10 tree-specific slopes, and 3 variances (<span class="math inline">\(\sigma_{\epsilon}^{2}, \sigma_{b_{0}}^{2}\)</span>, <span class="math inline">\(\sigma_{b_{1}}^{2}\)</span>).</p>
<p>This is a relatively complex model and included here only to show how the sampling design can be incorporated into the model formulation to achieve interpretable and parsimonious models and how this naturally leads to multiple random effects.</p>
<p>A further refinement of this model is to recognize that the measurements over time for each apple are likely not independent. Furthermore, diameter measurements on the same apple close in time are more strongly correlated than measurements further apart. Incorporating this correlation structure into the models leads to a <strong>mixed model with correlated errors</strong>.</p>
</section>
<section id="response-target-variable" class="level4">
<h4 class="anchored" data-anchor-id="response-target-variable">Response (Target) variable</h4>
<p>A model has inputs that are processed by an algorithm to produce an output. When the output is a variable to be predicted, classified, or grouped, we refer to it with different—but interchangeable—names as the <strong>response</strong> variable, or the <strong>target</strong> variable, or the <strong>dependent</strong> variable. We are not particular about what you call the variable, as long as we agree on what we are talking about—the left-hand side of the model.</p>
<p>The target variable is a random variable and can be of different types. This matters greatly because we have to match distributional assumptions to the natural type of the target. Applying an analytic method designed for continuous variables that can take on infinitely many values to a binary variable that takes on two values is ill advised. However, it happens. A lot.</p>
<p>The first distinction is whether the target variable is continuous or discrete.</p>
<ul>
<li><p><strong>Continuous</strong>: the number of possible values of the variable is not countable. Typical examples are physical measurements such as weight, height, length, pressure, temperature. If the values of a variable are countable but the cardinality is high, applying methods for continuous data can make sense—for example, number of days since birth.</p></li>
<li><p><strong>Discrete</strong>: the number of possible values is countable. Even if the number of possible values is infinite, the variable is still discrete. The number of fish caught per day does not have a theoretical upper limit, although it is highly unlikely that a weekend warrior will catch 1,000 fish. A commercial fishing vessel might.</p></li>
</ul>
<p>Discrete variables are further divided into the following groups:</p>
<ul>
<li><p><strong>Count Variables</strong>: the values are true counts, obtained by enumeration. There are two types of counts:</p>
<ul>
<li><p><strong>Counts per unit</strong>: the count relates to a unit of measurement, e.g., the number of fish caught per day, the number of customer complaints per quarter, the number of chocolate chips per cookie, the number of cancer incidences per 100,000.</p></li>
<li><p><strong>Proportions (Counts out of a total)</strong>: the count can be converted to a proportion by dividing it with a maximum value. Examples are the number of heads out of 10 coin tosses, the number of larvae out of 20 succumbing to an insecticide,</p></li>
</ul></li>
<li><p><strong>Categorical Variables</strong>: the values consist of labels, even if numbers are used for labeling.</p>
<ul>
<li><p><strong>Nominal variables</strong>: The labels are unordered, for example the variable “fruit” takes on the values “apple”, “peach”, “tomato” (yes, tomatoes are fruit but do not belong in fruit salad).</p></li>
<li><p><strong>Ordinal variables</strong>: the category labels can be arranged in a natural order in a lesser-greater sense. Examples are 1—5 star reviews or ratings of severity (“mild”, “modest”, “severe”).</p></li>
<li><p><strong>Binary variables</strong>: take on exactly two values (dead/alive, Yes/No, 1/0, fraud/not fraud, diseased/not diseased)</p></li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="supervised-and-unsupervised-methods" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="supervised-and-unsupervised-methods"><span class="header-section-number">12.3</span> Supervised and Unsupervised Methods</h2>
<p>Statistical learning and machine learning distinguish supervised and unsupervised methods of learning. Machine learning covers a third technique of learning not found in statistics, reinforcement learning.</p>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h3>
<div class="definition">
<div class="definition-header">
<p>Definition: Supervised Learning</p>
</div>
<div class="definition-container">
<p>Supervised learning trains statistical learning models through a target variable.</p>
</div>
</div>
<p><strong>Supervised learning</strong> is characterized by the presence of a target variable, also called a dependent variable, response variable, or output variable. This is the attribute we wish to model. The training and test data sets contain values for the target variable, in machine learning these values are often called the <strong>labels</strong> and are described as the “ground truth”. All other variables in the data set are potentially input variables. In short, we know the values of the target variable, now we need to use it in analytical methods to learn how outputs and inputs connect.</p>
<p>The goals of supervised learning are to</p>
<ul>
<li><p>Predict the target variable from input variables.</p></li>
<li><p>Develop a function that approximates the underlying relationship between inputs and outputs.</p></li>
<li><p>Understand the relationship between inputs and outputs.</p></li>
<li><p>Classify observations into categories of the target variable based on the input variables.</p></li>
<li><p>Group the observations into sets of similar data based on the values of the target variable and based on values of the inputs.</p></li>
<li><p>Reduce the dimensionality of the problem by transforming target and inputs from a high-dimensional to a lower-dimensional space.</p></li>
<li><p>Test hypotheses about the target variable.</p></li>
</ul>
<p>Studies can pursue one or more of these goals. For example, you might be interested in understanding the relationship between target and input variables and use that relationship for predictions.</p>
<p>The name supervised learning comes from thinking of learning in an environment that is supervised by a teacher. The teacher asks questions for which they know the correct answer (the ground truth) and judge a student’s response to the questions. The goal is to increase students’ knowledge as measured by the quality of their answers. But we do not want students to just memorize answers, we want to teach them to be problem solvers, to apply the knowledge to new problems, to generalize.</p>
<p>The parallel between the description of supervised learning in a classroom and training an algorithm on data is obvious: the problems asked by the teacher, the learning algorithm, are the data points, <span class="math inline">\(Y\)</span> is the correct answer, the inputs <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> are the information used by the students to answer the question. The discrepancy between question and answer is measured by <span class="math inline">\((y - \widehat{y})^2 = (y - \widehat{f}\left( x_{1},\cdots x_{p} \right))^2\)</span> or some other error metric. The training of the model stops when we found a model that generalizes well to previously unseen problems. We are not interested in models that follow the observed data too closely.</p>
<p><a href="#tbl-supervised-methods" class="quarto-xref">Table&nbsp;<span>12.1</span></a> contains a non-exhaustive list of algorithms and models you find in supervised learning.</p>
<div id="tbl-supervised-methods" class="striped quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-supervised-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.1: A sampling of supervised learning methods.
</figcaption>
<div aria-describedby="tbl-supervised-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table">
<colgroup>
<col style="width: 29%">
<col style="width: 33%">
<col style="width: 36%">
</colgroup>
<tbody>
<tr class="odd">
<td>Linear regression</td>
<td>Nonlinear regression</td>
<td>Regularized regression<br>
(Lasso, Ridge, Elastic nets)</td>
</tr>
<tr class="even">
<td>Local polynomial regression (LOESS)</td>
<td>Smoothing splines</td>
<td>Kernel methods</td>
</tr>
<tr class="odd">
<td>Logistic regression (binary &amp; binomial)</td>
<td>Multinomial regression (nominal and ordinal)</td>
<td>Poisson regression (counts and rates)</td>
</tr>
<tr class="even">
<td>Decision trees</td>
<td>Random forests</td>
<td>Bagged trees</td>
</tr>
<tr class="odd">
<td>Adaptive boosting</td>
<td>Gradient boosting machine</td>
<td>Extreme gradient boosting</td>
</tr>
<tr class="even">
<td>Naïve Bayes classifier</td>
<td>Nearest-neighbor methods</td>
<td>Discriminant analysis (linear and quadratic)</td>
</tr>
<tr class="odd">
<td>Principal component regression</td>
<td>Partial least squares</td>
<td>Generalized linear models</td>
</tr>
<tr class="even">
<td>Generalized additive models</td>
<td>Mixed models (linear and nonlinear)</td>
<td>Models for correlated data (spatial, time series)</td>
</tr>
<tr class="odd">
<td>Support-vector machines</td>
<td>Neural networks</td>
<td>Extreme gradient boosting</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>There is a lot to choose from, and for good reason. The predominant application of data analytics is supervised learning with batch (or mini-batch) data. In batch data analysis the data already exist as a historical data source in one place. We can read all records at once or in segments (called mini-batches). If we have to read the data multiple times, for example, because an iterative algorithm passes through the data at each iteration, we can do so.</p>
<p>Batch-oriented learning contrasts with online learning where the data on which the model is trained is generated and consumer in real time.</p>
</section>
<section id="unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning">Unsupervised Learning</h3>
<div class="definition">
<div class="definition-header">
<p>Definition: Unsupervised Learning</p>
</div>
<div class="definition-container">
<p>In unsupervised learning methods a target variable is not present.</p>
</div>
</div>
<p>Unsupervised learning does not utilize a target variable; hence it cannot predict or classify observations. However, we are still interested in discovering structure, patterns, and relationships in the data.</p>
<p>The term unsupervised refers to the fact that we no longer know the ground truth because there is no target variable. Hence the concept of a teacher who knows the correct answers and supervises the learning progress of the student does not apply. In unsupervised learning there are no clear error metrics by which to judge the quality of an analysis, which explains the proliferation of unsupervised methods and the reliance on heuristics. For example, a 5-means cluster analysis will find five groups of observations in the data, whether this is the correct number or not, and it is up to us to interpret what differentiates the groups and to assign group labels.</p>
<p>Often, unsupervised learning is used in an exploratory fashion, improving our understanding of the joint distributional properties of the data and the relationships in the data. The findings then help lead us toward supervised approaches.</p>
<p>A coarse categorization of unsupervised learning techniques also hints at their application:</p>
<ul>
<li><p><strong>Association analysis</strong>: which values of the variables <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> tend to occur together in the data? An application is market basket analysis, where the <span class="math inline">\(X\)</span>s are items are in a shopping cart (or a basket in the market), and <span class="math inline">\(x_{i} = 1\)</span> if the <span class="math inline">\(i\)</span><sup>th</sup> item is present in the basket and <span class="math inline">\(x_{i} = 0\)</span> if the item is absent. If items frequently appear together, bread and butter, or beer and chips, for example, then maybe they should be located close together in the store. Association analysis is also useful to build recommender systems: shoppers who bought this item also bought the following items </p></li>
<li><p><strong>Cluster analysis</strong>: can data be grouped based on <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> into sets such that the observations within a set are more similar to each other than they are to observations in other sets? Applications of clustering include grouping customers into segments. Segmentation analysis is behind loyalty programs, lower APRs for customers with good credit rating, and churn models.</p></li>
<li><p><strong>Dimension reduction</strong>: can we transform the inputs <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> into a set <span class="math inline">\(c_{1},\cdots,c_{k}\)</span>, where <span class="math inline">\(k \ll p\)</span> without losing relevant information? Applications of dimension reduction are in high-dimensional problems where the number of inputs is large relative to the number of observations. In problems with wide data, the number of inputs <span class="math inline">\(p\)</span> can be much larger than <span class="math inline">\(n\)</span>, which eliminates many traditional methods of analysis from consideration.</p></li>
</ul>
<p>Methods of unsupervised learning often precede supervised learning; the output of an unsupervised learning method can serve as the input to a supervised method. An example is dimension reduction through principal component analysis (PCA) prior to supervised regression. Suppose you have <span class="math inline">\(n\)</span> observations on a target variable <span class="math inline">\(Y\)</span> and a large number of potential inputs <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> where <span class="math inline">\(p\)</span> is large relative to <span class="math inline">\(n\)</span>. PCA computes linear combinations of the <span class="math inline">\(p\)</span> inputs that account for decreasing amounts of variability among the <span class="math inline">\(X\)</span>s. These linear combinations are called the principal components. For example, the first principal component explains 70% of the variability in the inputs, the second principal component explains 20% and the third principal component 5%. Rather than building a regression model with <span class="math inline">\(p\)</span> predictors, we use only the first three principal components as inputs in the regression model. The resulting regression model is called a principal component regression (PCR) because its inputs are the result of a PCA. The PCA is an unsupervised model because it does not use information about <span class="math inline">\(Y\)</span> in forming the principal components. If <span class="math inline">\(p = 250\)</span>, using the first three principal components replaces</p>
<p><span class="math display">\[Y = \beta_{0} + \beta_{1}{\ x}_{1} + \beta_{2}x_{2} + \beta_{3}x_{3} + \beta_{4}x_{4} + \cdots + \beta_{250}x_{250} + \epsilon\]</span></p>
<p>with</p>
<p><span class="math display">\[Y = \alpha_{0} + \alpha_{1}c_{1} + \alpha_{2}c_{2} + \alpha_{3}c_{3} + \epsilon\]</span></p>
<p>where <span class="math inline">\(c_{1}\)</span> denotes the first principal component, itself a linear combination of the 250 inputs</p>
<p><span class="math display">\[c_{1} = \gamma_{1}x_{1} + \gamma_{2}x_{2} + \gamma_{3}x_{3} + \cdots + \gamma_{250}x_{250}\]</span></p>
</section>
<section id="reinforcement-learning" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning">Reinforcement Learning</h3>
<p>Reinforcement learning (RL) is unique to machine learning and does not fall neatly in the supervised/unsupervised learning buckets. It is a very powerful method that received a lot of attention when algorithms could be trained on data to play games extremely well.</p>
<p>The approach, based on reinforcement learning, was fundamentally different from the expert system-based approach used so far to teach computers how to play games. An expert system translates the rules of the game into machine code and adds strategy logic. For example, the Stockfish open-source chess program, released first in 2008, has developed with community support into (one of) the best chess engines in the world. In 2017, Google’s DeepMind released AlphaZero, a chess system trained using reinforcement learning. After only 24 hours of training, the data-driven AlphaZero algorithm crushed Stockfish, the best chess engine humans have been able to build over 10 years.</p>
<p>Previously, Google’s DeepMind had developed AlphaGo, a reinforcement-trained system that beat the best Go player in the world, Lee Sedol, four to one. This was a remarkable achievement as Go had been thought to be so complex and requiring intuition that would escape computerization at the level of expert players.</p>
<p>In reinforcement learning, an agent (a player) is taking actions (makes moves) in an environment (the game). The agent learns by interacting with the environment by receiving feedback on the moves. Actions are judged by a reward function (a score) and the system is trained to maximize the sum of future rewards. In other words, given your current position in the game, choose the next move to maximize the score from here on out.</p>
<p>An interesting difference between AlphaGo and AlphaZero is the nature of the training data. Both systems are trained using reinforcement learning. AlphaGo was trained on records of many expert-level games. It was trained to play against historic experts. Success was getting better compared to how human experts played. AlphaZero was trained by playing against itself. Success was beating its former self.</p>
<p>Unlike supervised learning, inputs and outputs do not need to be present in reinforcement learning. The technique is commonly used in robotics, gaming, and recommendation systems.</p>
<p>Until recently, a limitation of RL was the need for a good reward function. It is important that actions in the environment are properly judged. In situation where the result of a move is difficult to judge, reinforcement learning was difficult to apply. For example, in natural language processing, where an action produces some prose, how do we rate the quality of the answer?</p>
<p>This was the problem faced by systems like Chat-GPT. How do you score the answer produced during training to make sure the algorithm continuously improves? The solution was a form of reinforcement learning modified by human intervention. RLHF, reinforcement learning with human feedback, uses human interpreters to assign scores to the actions (the Chat-GPT answers).</p>
<p>In 2017, when AlphaGo beat Lee Sedol, it was thought that reinforcement learning would change the world. Despite its remarkable achievement in gameplay and robotics, the impact of RL fell short of expectations.</p>
<div id="fig-sl-Yann-leCun" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-Yann-leCun-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/YannLeCun_on_RL.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-Yann-leCun-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.2: Yann LeCun weighs in on the impact of reinforcement learning (RL).
</figcaption>
</figure>
</div>
<p>Why did RL fall short? Developing and training reinforcement learning models is an expensive undertaking. The barrier to entry is very high, limiting RL research and development to large tech-savvy organizations. The main reason is the Sim2Real problem mentioned in the tweet above. Reinforcement learning trains an agent in a simulated, artificial environment. The real world is much more complex and transferring training based on simulation to reality is difficult. The RL agents end up performing poorly in real applications.</p>
</section>
</section>
<section id="regression-and-classification" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="regression-and-classification"><span class="header-section-number">12.4</span> Regression and Classification</h2>
<section id="regression-and-the-regression-to-the-mean-fallacy" class="level3">
<h3 class="anchored" data-anchor-id="regression-and-the-regression-to-the-mean-fallacy">Regression and the Regression to the Mean Fallacy</h3>
<p>The term <em>regression</em> was coined by Sir Francis Galton in 1877 in his study of genetics. Galton observed a relationship between physical attributes of offspring and their parents. He found that offspring deviated less from the mean value of the population than their parents did. For example, taller parents tend to have taller children, but children of taller parents tend to be shorter than their parents and children of shorter parents tend to be taller than their parents.</p>
<p>The cause Galton attributed to this phenomenon—which he called <em>regression toward mediocrity</em>—is controversial, his arguments had implications about natural selection and eugenics. As a statistical phenomenon, it is well understood. Attributes are distributed randomly; if you draw an extreme observation from a symmetric distribution, then a subsequent draw is likely to be less extreme, there is a <strong>regression to the mean</strong>.</p>
<p><a href="#fig-sl-regression-to-the-mean" class="quarto-xref">Figure&nbsp;<span>12.3</span></a> displays this phenomenon based on the distribution of HDL cholesterol values in a single person. Our cholesterol levels vary from day to day and if the distribution is normally distributed, it might look like the density in the figure, centered at a mean of 50 mg/dl. Suppose you measure a person’s HDL cholesterol, and it results in a first measurement of 30 mg/dl. The value is on the low side of the distribution, but it is not implausible. A follow-up measurement is more likely to be observed near the center of the distribution where most of the probability density is located. A second measurement might thus return a value of 55 mg/dl. A regression to the mean occurred between the first and second measurements.</p>
<div id="fig-sl-regression-to-the-mean" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-regression-to-the-mean-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Regression_to_the_mean.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" data-glightbox="description: .lightbox-desc-2"><img src="images/Regression_to_the_mean.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-regression-to-the-mean-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.3: An example of regression to the mean. An extreme observation is more likely to be followed by a less extreme observation, one that falls near the center of the distribution.
</figcaption>
</figure>
</div>
<p>Another fun example of regression to the mean is answering multiple-choice questions on an exam at random. If you administer the exam, all students answer questions completely at random, and you choose the students with the top 10% of scores to take the exam again—choosing answers at random again—then their scores will regress to the mean. The top 10% in the first test will get about ½ the questions correct. Their initial high scores were due to luck.</p>
<p>The term regression has evolved to describe statistical methods that model the mean behavior of an attribute and separate it from non-systematic, random behavior. The regression to the mean phenomenon does not mean regression methods are bad. It is a fact of random variation and a real fallacy when interpreting data. In the cholesterol example, is the change from 30 to 50 mg/dl of HDL due to natural variation or due to a systematic effect, for example, a medical intervention? Regression is intended to separate signal from noise. The regression to the mean fallacy is to misinterpret random variation as a signal.</p>
<div class="example">
<div class="example-header">
<p>Example: Testing a Treatment Effect</p>
</div>
<div class="example-container">
<p>You want to determine whether a change in diet reduces the risk of heart disease. From a group of individuals, you select those at greatest risk of heart disease and put them on the diet. After some time, you reassess their risk of heart disease.</p>
<p>Because of regression to the mean, the follow-ups will likely show an improvement even if the diet has no effect at all. The correct way of studying whether the diet has an effect is to randomly divide the individuals into two groups and assign the diet to one group (the treated group) while the other group stays on their normal diet. If the individuals in the treated group improve more than the untreated group, to a degree that cannot be attributed just to chance, then we can make a statement that the diet is effective in reducing the risk of heart disease.</p>
</div>
</div>
</section>
<section id="regression-models" class="level3">
<h3 class="anchored" data-anchor-id="regression-models">Regression Models</h3>
<div class="definition">
<div class="definition-header">
<p>Definition: Regression Model</p>
</div>
<div class="definition-container">
<p>A <strong>regression model</strong> is a statistical model that describes how the mean of a random variable depends on other factors. The factors are often called inputs, predictor variables, predictors, or independent variables.</p>
<p>The variable whose mean is modeled is called the target variable, response variable, or dependent variable.</p>
</div>
</div>
<p>Regression models are not just for continuous response data, they apply to all response types. The defining characteristic is to model the mean as a function of inputs:</p>
<p><span class="math display">\[\text{E}\lbrack Y\rbrack = f\left( x_{1},\cdots,x_{p},\theta_{1},\cdots,\theta_{k} \right)\]</span></p>
<p>This expression explicitly lists parameters <span class="math inline">\(\theta_{1},\cdots,\theta_{k}\)</span> in the mean function. All regression models involve the estimation of unknown, fixed quantities (=parameters), even if they do so obliquely. As we have seen in the non-linear regression example earlier, the number of parameters and the number of inputs do not have to be directly related.</p>
<p>Even if the target variable is categorical, we might be interested in modeling the mean of the variable. The simplest case of categorical variables are binary variables with two levels (two categories). This is the domain of logistic regression. As seen earlier, if the categories are coded numerically as <span class="math inline">\(Y = 1\)</span> for the category of interest (the “event”) and <span class="math inline">\(Y = 0\)</span> for the “non-event” category, the mean of <span class="math inline">\(Y\)</span> is a probability. A regression model for a binary target variable is thus a model to predict probabilities. It is sufficient to predict one of the probabilities in the binary context, we call this the event probability <span class="math inline">\(\pi\)</span>. The complement can be obtained by subtraction, <span class="math inline">\(1 - \pi\)</span>.</p>
<p>Extending this principle to more than two categories leads to regression models for <strong>multinomial</strong> data. If the category variable has <span class="math inline">\(k\)</span> levels with labels <span class="math inline">\(C_{1},\cdots,C_{k}\)</span>, we are dealing with <span class="math inline">\(k\)</span> probabilities; <span class="math inline">\(\pi_{j}\)</span> is the probability to observe the label <span class="math inline">\(C_{j}\)</span>. Suppose that we are collecting data on ice cream preferences on college campuses. A random sample of students are given three ice cream brands in a random order and report the taste as <span class="math inline">\(C_{1} =\)</span>’yuck’, <span class="math inline">\(C_{2} =\)</span>’meh’, and <span class="math inline">\(C_{3} =\)</span>’great’. Modeling these data with regression techniques, we develop a model for the probability to observe category <span class="math inline">\(j\)</span> as a function of inputs. A multinomial version of logistic regression looks like the following:</p>
<p><span class="math display">\[\text{Pr}\left( Y = j \right) =
\frac{\exp\left\{ \beta_{0j} + \beta_{1j}x_1 + \cdots + \beta_{pj}x_p \right\}}
     {\sum_{l=1}^k \exp\{\beta_{0l} + \beta_{1l}x_1 + \cdots + \beta_{pl}x_p\}}
\]</span></p>
<p>This is a rather complicated model, but we will see later that it is a straightforward generalization of the two-level case. Instead of one linear predictor we now have separates predictors for the categories. The point of introducing the model here is to show that even in the categorical case we can apply regression methods—they predict category probabilities rather than the mean of a continuous variable.</p>
</section>
<section id="classification-problems" class="level3">
<h3 class="anchored" data-anchor-id="classification-problems">Classification Problems</h3>
<p>Classification applies to categorical variables, binary and multinomial variables that take on a discrete number of categories, <span class="math inline">\(k\)</span>. In the binary case <span class="math inline">\(k = 2\)</span>, and in the multinomial case <span class="math inline">\(k &gt; 2\)</span>.</p>
<p>The classification problem is to predict not the mean of the variable but to assign a category to an observation. The algorithm that maps from input variables to a category is called a <strong>classifier</strong> and the assignment decision is called the <strong>classification rule</strong>. Applications of classifications occur in many domains, for example,</p>
<ul>
<li><p><strong>Medical diagnosis</strong>: Given a patient’s symptoms, assign a medical condition.</p></li>
<li><p><strong>Financial services</strong>: Determine whether a payment transaction is fraudulent.</p></li>
<li><p><strong>Customer intelligence</strong>: Assign a new customer to a customer profile (segmentation).</p></li>
<li><p><strong>Computer vision</strong>: Detect defective items on an assembly line.</p></li>
<li><p><strong>Computer vision</strong>: Identify objects in an image.</p></li>
<li><p><strong>Text classification</strong>: Categorize incoming emails as spam.</p></li>
<li><p><strong>Digital marketing</strong>: predict which advertisement a user is most likely to click.</p></li>
<li><p><strong>Search engine</strong>: Given a user’s query and search history predict what link they will follow.</p></li>
</ul>
<p>Classification problems are also interested in predicting. Rather than the mean of a random variable, they predict the membership in a category.</p>
<p>While the mean-squared prediction error is the standard measure of model performance in regression models, in classification models the quality of a classifier is measured by the misclassification rate (MCR) and related statistics based on contrasting the number of correct and incorrect classifications.</p>
<section id="misclassification-rate" class="level4">
<h4 class="anchored" data-anchor-id="misclassification-rate">Misclassification rate</h4>
<div class="definition">
<div class="definition-header">
<p>Definition: Misclassification Rate</p>
</div>
<div class="definition-container">
<p>The <strong>misclassification rate</strong> (MCR) of a classifier is the proportion of observations that are predicted to fall into the wrong category. If <span class="math inline">\(y_{i}\)</span> is the observed category of the <span class="math inline">\(i\)</span>th data point, and <span class="math inline">\({\widehat{y}}_{i}\)</span> is the predicted category, the MCR for a sample of <span class="math inline">\(n\)</span> observations is</p>
<p><span class="math display">\[\text{MCR} = \frac{1}{n}\sum_{i = 1}^{n}{I\left( y_{i} \neq {\widehat{y}}_{i} \right)}\]</span></p>
<p><span class="math inline">\(I(x)\)</span> is the indicator function,</p>
<p><span class="math display">\[I(x) = \left\{ \begin{matrix} 1 &amp; \text{if }x\text{ is true} \\ 0 &amp; \text{otherwise} \end{matrix} \right. \]</span></p>
</div>
</div>
<p>The misclassification rate is simply the proportion of observations we predicted incorrectly. the term <span class="math inline">\(\sum_{i = 1}^{n}{I\left( y_{i} \neq {\widehat{y}}_{i} \right)}\)</span> counts the number of incorrect predictions. The complement of MCR, the proportion predicted correctly, is called the <strong>accuracy</strong> of the classification model.</p>
</section>
<section id="from-probabilities-to-classification" class="level4">
<h4 class="anchored" data-anchor-id="from-probabilities-to-classification">From probabilities to classification</h4>
<p>Regression methods play an important role in classification problems because classification rules are tied to the likelihood to observe categories. Suppose we have a three-category problem with <span class="math inline">\(\pi_{1} = 0.7,\ \pi_{2} = 0.2,\pi_{3} = 0.1\)</span>, and you are asked to predict the category of the next randomly drawn observation. The most likely category to appear is <span class="math inline">\(C_{1}.\)</span></p>
<p>This classification rule is known as the Bayes classifier.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Bayes Classifier</p>
</div>
<div class="definition-container">
<p>The Bayes classifier assigns an observation with inputs <span class="math inline">\(x_{1},\cdots,x_{p}\)</span> to the class <span class="math inline">\(C_{j}\)</span> for which</p>
<p><span class="math display">\[\Pr(Y = j \, | \, x_{1},\cdots,x_{p})\]</span></p>
<p>is largest.</p>
</div>
</div>
<p>The Bayes classifier is written as a conditional probability, the probability to observe category <span class="math inline">\(C_{j}\)</span>, given the values of the input variables. The reason for this will become clearer later when we cover different methods for obtaining category probabilities. Some methods for deriving category probabilities assume that the <span class="math inline">\(X\)</span>s are random. In regression problems it is assumed that they are fixed, so there is no difference between the unconditional probability <span class="math inline">\(\Pr\left( Y = j \right)\)</span> and the conditional probability <span class="math inline">\(\Pr( Y = j \, | \, x_1,\cdots,x_p)\)</span>.</p>
<p>We can now see the connection between regression and classification. Develop first a regression model that predicts the category probabilities <span class="math inline">\(\Pr( Y = j \, | \, x_1,\cdots,x_p)\)</span>. Then apply a classification rule to assign a category based on the predicted probabilities. If you go with the Bayes classifier, you choose the category that has the highest predicted probability. For a 2-category problem where events are coded as <span class="math inline">\(Y=1\)</span> and non-events are coded as <span class="math inline">\(Y=0\)</span>, this means classifying an observation as an event if</p>
<p><span class="math display">\[\Pr\left( Y = 1\, | \,x_1,\cdots,x_p \right) \geq 0.5\]</span></p>
</section>
</section>
</section>
<section id="prediction-and-explanation" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="prediction-and-explanation"><span class="header-section-number">12.5</span> Prediction and Explanation</h2>
<p>The goal in developing models is to perform inference, to reach conclusions and make decisions based on data. Broadly, the goals fall into two categories:</p>
<ul>
<li><p><strong>Predictive inference</strong>: concerned with developing an algorithm that predicts the target variable well and generalizes to observations not used in training the model.</p></li>
<li><p><strong>Explanatory inference</strong>: also called <strong>confirmatory</strong> inference, it is concerned with understanding the relationship between target and input variables, understanding the relevance of the inputs, and testing hypotheses about the target variable.</p></li>
</ul>
<p>In machine learning, the term <em>inference</em> is used to describe the process of predicting new observations after training a model. Statisticians call this part of data analytics <strong>scoring</strong> the model. The predicted value is the “score” associated with the new observation. Our view of inference is broader than just predicting (scoring) observations. It includes any application of the trained model to derive information of interest: hypothesis testing, confidence and prediction intervals, predicted values, forecasts, etc.</p>
<p>Data projects are not necessarily either predictive or confirmatory. Many projects have elements of both, as in the following example.</p>
<div class="example">
<div class="example-header">
<p>Example: Dose-response study of insect mortality</p>
</div>
<div class="example-container">
<p><a href="#fig-sl-insect-mortality" class="quarto-xref">Figure&nbsp;<span>12.4</span></a> shows logits of sample proportions in a dose-response study of insect larvae mortality as a function of the concentration of an insecticide. Suppose <span class="math inline">\(y_{i}\)</span> denotes the number of larvae out of <span class="math inline">\(n_{i}\)</span> that succumb to the insecticide at concentration <span class="math inline">\(x_{i}\)</span>. The right panel of the figure shows the logit of the sample proportion <span class="math inline">\(p_{i} = \frac{y_{i}}{n_{i}}\)</span>,</p>
<p><span class="math display">\[\log\left\{ \frac{p_{i}}{1 - p_{i}} \right\}\]</span></p>
<p>as a function of the log insecticide concentration. A simple linear model seems appropriate,</p>
<p><span class="math display">\[\log\left\{ \frac{\text{E}\lbrack p_{i}\rbrack}{1 - \text{E}\lbrack p_{i}\rbrack} \right\} = \beta_0 + \beta_1\log_{10}x_i\]</span></p>
<p>Note that the expected value <span class="math inline">\(\text{E}\left\lbrack p_{i} \right\rbrack\)</span> is a probability. This model is a generalization of logistic regression for binary data (a 0/1 response) to binomial sample proportions. <span class="math inline">\(\text{E}\left\lbrack p_{i} \right\rbrack = \pi_{i}\)</span> is the probability that an insect dies when <span class="math inline">\(\log_{10}x_{i}\)</span> amount of insecticide is applied.</p>
<div id="fig-sl-insect-mortality" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-insect-mortality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/InsectMortality.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-insect-mortality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.4: Logits of larvae mortality sample proportion against insecticide concentration and log concentration.
</figcaption>
</figure>
</div>
<p>The investigators want to understand the relationship between larvae mortality and insecticide concentration. The parameter estimate for <span class="math inline">\(\beta_{1}\)</span> is of interest, it describes the change in logits that corresponds to a unit-level change in the log concentration. A hypothesis test for <span class="math inline">\(\beta_{1}\)</span> might compare the dose-response in this study with the known dose-response slope <span class="math inline">\(c\)</span> of a standard insecticide. The null hypothesis of this test specifies that the insecticide is as effective as the standard:</p>
<p><span class="math display">\[H_{0}:\beta_{1} = c\]</span></p>
<p>Another value of interest in dose-response studies is the concentration that achieves a specified effect. For example, the lethal dosage <span class="math inline">\(LD_{50}\)</span> is the concentration that kills 50% of the subjects. Determining the <span class="math inline">\(LD_{50}\)</span> value is known as an <strong>inverse prediction</strong> problem: rather than predicting <span class="math inline">\(\text{E}\lbrack Y\rbrack\)</span> for a given value of <span class="math inline">\(X\)</span>, we are interested in finding the value <span class="math inline">\(X\)</span> that corresponds to a given a value of <span class="math inline">\(\text{E}\lbrack Y\rbrack\)</span>.</p>
<div id="fig-sl-insect-mortality2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-insect-mortality2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/InsectMortality_2.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-insect-mortality2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.5: Fitted dose-response curve and inverse prediction of $LD_{50}$. The $LD_{50}$ is calculated from the value where the vertical line intersects the horizontal axis.
</figcaption>
</figure>
</div>
<p>The <span class="math inline">\(LD_{50}\)</span> value can be calculated from the model equation. More generally, we can find any value on the x-axis that corresponds to a particular mortality rate <span class="math inline">\(\alpha\)</span> by solving the following equation for <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[\text{logit}(\alpha) = \log\left\{ \frac{\alpha}{1 - \alpha} \right\} = \beta_0 + \beta_1\log_{10}x_\alpha\]</span></p>
<p>The solution is</p>
<p><span class="math display">\[x_{\alpha} = 10^{\frac{\left( \text{logit}(\alpha) - \beta_{0} \right)}{\beta_{1}}}\]</span></p>
<p>For the special value <span class="math inline">\(\alpha = 0.5\)</span>, the <span class="math inline">\(LD_{50}\)</span> results,</p>
<p><span class="math display">\[LD_{50} = 10^{\frac{- \beta_{0}}{\beta_{1}}}\]</span></p>
<p>In addition to hypothesis testing about <span class="math inline">\(\beta_{1}\)</span> and calculating the <span class="math inline">\(LD_{50}\)</span>, the investigators are also interested in predicting the mortality rate at concentrations not used in the study.</p>
<p>The inference in the study has explanatory (confirmatory) and predictive elements.</p>
</div>
</div>
<p>It is important to point out that many studies are not completely confirmatory or predictive, because models that are good at confirmatory inference are not necessarily good at predicting. Similarly, models that predict well are not necessarily good at testing hypotheses. Interpretability of the model parameters is important for confirmatory inference because hypotheses about the real world are cast as statements about the model parameters. Many disciplines place a premium on interpretability, e.g., biology, life sciences, economics, physical sciences, geosciences, natural resources, financial services. Experiments designed to answer specific questions rely on analytic methods designed for confirmatory inference.</p>
<p>Interpretability of the model parameters might not be important for a predictive model. A biased estimator that reduces variability and leads to a lower mean-squared prediction error (see the next section) can be appealing in a predictive model but can be unacceptable in a project where confirmatory inference is the primary focus.</p>
</section>
<section id="correlation-and-causation" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="correlation-and-causation"><span class="header-section-number">12.6</span> Correlation and Causation</h2>
<section id="correlation" class="level3">
<h3 class="anchored" data-anchor-id="correlation">Correlation</h3>
<p>You learn in any basic statistics course that ``correlation is not causation’’. Two random variables are correlated if they vary together, values of one variable tend to be associated with certain values of the other variable.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Correlation</p>
</div>
<div class="definition-container">
<p>The <strong>correlation</strong> between random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, denoted <span class="math inline">\(\rho_{xy}\)</span> or <span class="math inline">\(\text{Corr}(X,Y)\)</span>, is the ratio of their <strong>covariance</strong>, <span class="math inline">\(\text{Cov}(X,Y)\)</span>, and the product of their standard deviations:</p>
<p><span class="math display">\[\text{Cov}(X,Y) = \text{E}\lbrack\left( X - \text{E}\lbrack X\rbrack \right)\left( Y - \text{E}\lbrack Y\rbrack \right) = \text{E}\lbrack XY\rbrack - \text{E}\lbrack X\rbrack\text{E}\lbrack Y\rbrack\]</span></p>
<p><span class="math display">\[\rho_{xy} = \text{Corr}(X,Y) = \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}\lbrack X\rbrack\text{Var}\lbrack Y\rbrack}}\]</span></p>
<p>When the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is non-zero, we say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are related to each other or are associated with each other. The covariance measures how <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> vary jointly: as <span class="math inline">\(X\)</span> deviates from its mean, how does <span class="math inline">\(Y\)</span> change relative to its mean? When large values of <span class="math inline">\(X\)</span> are associated with large values of <span class="math inline">\(Y\)</span>, the correlation is positive. Dividing by the product of the standard deviations scales the correlation so that <span class="math inline">\(- 1 \leq \rho_{xy} \leq 1\)</span>.</p>
</div>
</div>
<p>The correlation—like the covariance—is an expected value, it describes long-run behavior of the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The correlation is not directly knowable and is estimated from pairs of observations <span class="math inline">\((x_1, y_1),\cdots,\ (x_n, y_n)\)</span>. The most common estimator when <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous random variables is the Pearson product-moment correlation coefficient.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Pearson product-moment correlation coefficient</p>
</div>
<div class="definition-container">
<p>The Pearson product-moment estimate of the correlation <span class="math inline">\(\text{Corr}(X,Y),\)</span> based on a sample <span class="math inline">\((x_1, y_1),\cdots,(x_n,y_n),\)</span> is given by</p>
<p><span class="math display">\[{\widehat{\rho}}_{xy} = \frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}}\]</span></p>
<p><span class="math display">\[S_{xy} = \sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)\left( y_{i} - \overline{y} \right) = \sum_{i = 1}^{n}{x_{i}y_{i}} - n\overline{x}\overline{y}}\]</span></p>
<p><span class="math display">\[S_{xx} = \sum_{i = 1}^{n}{\left( x_{i} - \overline{x} \right)^{2} = \sum_{i = 1}^{n}x_{i}^{2} - n{\overline{x}}^{2}}\]</span></p>
<p><span class="math display">\[S_{yy} = \sum_{i = 1}^{n}{\left( y_{i} - \overline{y} \right)^{2} = \sum_{i = 1}^{n}y_{i}^{2} - n{\overline{y}}^{2}}\]</span></p>
<p><span class="math inline">\(S_{xx}\)</span> and <span class="math inline">\(S_{yy}\)</span> are called the observed sum of squares of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, respectively. <span class="math inline">\(S_{xy}\)</span> is the observed sum of cross-products between the variables.</p>
</div>
</div>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are correlated, we are very careful not to say that <span class="math inline">\(X\)</span> <strong>causes</strong> <span class="math inline">\(Y\)</span> or that <span class="math inline">\(Y\)</span> <strong>causes</strong> <span class="math inline">\(X\)</span>. The crow of a rooster and the rising of the sun are correlated, but the rooster’s crow does not cause the sun to rise.</p>
<p>When one event is the result of another event, the events have a cause—effect relationship. Flipping a light switch causes the light to turn on or off. Taking ibuprofen causes the inflammation to subside. Nothing in the definition or formulas for <span class="math inline">\(\rho_{xy}\)</span> or <span class="math inline">\({\widehat{\rho}}_{xy}\)</span> implies causation.</p>
</section>
<section id="spurious-correlation" class="level3">
<h3 class="anchored" data-anchor-id="spurious-correlation">Spurious Correlation</h3>
<p>Correlation itself is not a reliable concept either. Correlation can be the result of a direct relationship between the variables, or it can be induced by mediating or latent (confounding) variables. Correlations that are not the result of direct relationships are called <strong>spurious</strong>.</p>
<div class="example">
<div class="example-header">
<p>Example: Donuts and High School Graduation</p>
</div>
<div class="example-container">
<p>The number of high school graduates and donut consumption are positively correlated—with increasing donut consumption the number of high school graduates increases. This is a spurious correlation induced by the latent variable population size. Both variables increase over time with an increasing population. Even if the proportion of high school graduates and the donut consumption per person are unrelated, the total numbers will be higher in a larger population.</p>
<p><img src="images/spurious3.jpg" id="fig-sl-donut-spurious" class="img-fluid quarto-figure quarto-figure-center anchored" style="width:80.0%" alt="Spurious relationship between donut consumption and high school graduation. Source.">.</p>
</div>
</div>
<div class="example">
<div class="example-header">
<p>Example: Confounded Customer Churn</p>
</div>
<div class="example-container">
<p>A common request to the data science team is to use data analytics to improve customer retention. That starts with understanding why customers leave the company (churn).</p>
<p>An analysis of historical customer data reveals a positive correlation between churn rate and discounts offered. This association is induced by a confounding factor: customer satisfaction. Customers who are dissatisfied are more likely to complain to customer service, which results in discount offers to entice the complaining customer to stay with the vendor. The discount offer cannot overcome the customer’s dissatisfaction and they churn the company. Without understanding the confounding factor—customer satisfaction—an analysis of the raw data could suggest that higher discount rates lead to higher customer attrition.</p>
</div>
</div>
<div class="example">
<div class="example-header">
<p>Example: Storks and Babies</p>
</div>
<div class="example-container">
<p>In central Europe a persistent myth is that storks bring babies. The origin of the association probably goes back to medieval days when conception was more common in mid-summer during the celebration of the summer solstice which is also a pagan holiday of marriage and fertility. The white stork is a migratory bird that flies to Africa in the fall and returns to Europe nine months later. The return of the storks coincided with the arrival of newborns; the connection was made that storks brought the babies.</p>
<p>Although the myth has been debunked, there have been several studies of the connection between fertility and the stork abundance. Neyman (1952) describes a study of 54 counties that comprises the following attributes:</p>
<p><span class="math inline">\(W\)</span>: Number of women of child-bearing age in the county (in 10,000)</p>
<p><span class="math inline">\(S\)</span>: Number of storks in the county</p>
<p><span class="math inline">\(B\)</span>: Number of babies born in the county</p>
<p>Since it is likely that these numbers increase with the size of the county, the variables analyzed were <span class="math inline">\(Y = B/W\)</span> and <span class="math inline">\(X = S/W\)</span>, the birth rate per 10,000 women and the density of storks per 10,000 women. <a href="../proj/lifecycle.html#fig-proj-intuition-storks" class="quarto-xref">Figure&nbsp;<span>3.9</span></a> reproduces the scatterplot of <span class="math inline">\(Y\)</span> vs <span class="math inline">\(X\)</span>.</p>
<p>There seems to be a clear trend, the birth rate increases with the stork density. Is that evidence the myth is correct after all?</p>
<p>The reason for the apparent trend is the use of <span class="math inline">\(W\)</span> in the denominator of both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Even if <span class="math inline">\(S\)</span> and <span class="math inline">\(B\)</span> are unrelated, the ratio with a common variable induces a correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
<p>There are many examples of spurious correlations—from hilarious to frightening—and these are often trotted out to try and explain the difference between correlation and causation. The debate between correlation and causation is not because correlations can be spurious. The rooster crows when the sun rises, this is not a spurious relationship. But the rooster does not cause the sun to rise. Correlation of any kind, true dependence or spurious, does not imply causation—but then what does?</p>
<p>Smoking causes lung cancer but smoking does not cause alcoholism. However, there is an association (correlation) between smoking and alcoholics. How did we establish causation in one instance and correlation in the other? The battle for the statement “smoking causes lung cancer” raged for many years and it was not straightforward to settle the question based on the established methodology for establishing causation.</p>
</section>
<section id="experimentation" class="level3">
<h3 class="anchored" data-anchor-id="experimentation">Experimentation</h3>
<p>Statisticians are taught that causation can only be established by following rigorous principles of designed experiments, systematically varying factors of interest (treatments) and controlling other factors in a scheme that allocates experimental units at random to treatments. In a designed experiment we control the data-generating mechanism and create the data to measure the effect of an intervention. Because we are manipulating the environment, and because influences other than the ones we are interested in are neutralized by randomization, can we answer the question <strong>why</strong> something happened with confidence.</p>
<p>On the other hand, when we only observe the outcome of a data-generating process, rather than making the data-generating process, we cannot say why we observe what we observe. Data in an observational study can tell us that those who took a drug fared better than those who did not take the drug; but the data cannot tell us why they did better. The two groups could be different in other ways that explain a better health outcome.</p>
<p>This thinking is deeply embedded in scientific methodology; the line of inquiry whether smoking causes cancer would have been considered unscientific a few decades ago. A designed experiment in which some randomly chosen individuals are forced to smoke is not possible. In the absence of data from a designed experiment it was argued successfully for a long time that cause-and-effect between smoking and lung cancer has not been established—despite overwhelming evidence to the contrary.</p>
<p>The difference between the experimental and the observational study is doing versus seeing. Designed experiments are the statistician’s way of “doing”, but it is not always possible to manipulate and intervene with systems in this way. Ethical concerns might rule out giving harmful treatments. Some effects can only be assessed over long periods of time and maintaining control of other effects over time can be difficult. Some systems are altered by interventions in ways that make inferences about the original state meaningless. Some systems defy randomization. If you cannot randomize the stock market, how can we establish that higher returns were caused by a change in trading algorithm? How can we establish that human activity causes climate change? Traditional designed experimentation cannot be used. A prohibition to think about causation unless we are in a randomized controlled trial is not helpful.</p>
<p>In our daily lives we make causal inferences, not statistical ones. Human intuition is grounded in causal logic. When I gradually push a book over the edge of a table it will eventually fall off the table, caused by gravity. I do not need to repeat this 20 times to convince me that what was observed—the book fell—was just incredibly unlikely. Human intuition is sufficient to conclude that the physical therapy reduced the pain from tennis elbow. Something was done (to us, physical therapy) and we see the effect (on us, pain reduction). We do not require a statistical experiment to figure out that we have been helped. On the other hand, if we decide among treatment alternatives for tennis elbow, the existence of such experiments can be helpful in deciding on a treatment plan.</p>
</section>
<section id="the-ladder-of-causation" class="level3">
<h3 class="anchored" data-anchor-id="the-ladder-of-causation">The Ladder of Causation</h3>
<p>In their influential (cult) text “The Book of Why”, Judea Pearl and Dana MacKenzie introduce the Ladder of Causation, three distinct levels of cognitive ability: seeing, doing, and imagining.</p>
<div id="fig-sl-ladder-of-causation" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-ladder-of-causation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/A-depiction-of-The-Ladder-of-Causation-Republished-with-permission-from-Ref-15.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" data-glightbox="description: .lightbox-desc-3"><img src="images/A-depiction-of-The-Ladder-of-Causation-Republished-with-permission-from-Ref-15.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-ladder-of-causation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.6: The Ladder of Causation according to Pearl and MacKenzie.
</figcaption>
</figure>
</div>
<section id="first-rungseeing" class="level4">
<h4 class="anchored" data-anchor-id="first-rungseeing">First rung—seeing</h4>
<p>Seeing (observing) means detection of regularities and irregularities in the environment and acting on it. Most animals have this cognitive ability. An owl observes the movement of its prey and reacts to it. It recognizes regular and irregular patterns—healthy versus unhealthy prey—and changes its reaction to the environment. The first rung of the ladder of causation is where questions are answered by observing. The typical question is “What if I observe …?” A this rung of the ladder we find relationships and associations but cannot establish causality. We cannot determine why something happened.</p>
<p>Modifying an example given by Pearl and MacKenzie, suppose the manager of a grocery store wonders how likely someone who buys diapers also buys a 6-pack of beer. From the database of store sales, we can estimate the probability Pr(customer buys a 6-pack of beer) and the conditional probability Pr(customer buys a 6-pack of beer | customer also bought diapers).</p>
<p>The conditional probability is a measure of the association of the two events: buying diapers and buying beer. We cannot learn from this information whether increasing the price of diapers would affect beer sales. Even if the database of store sales contains sales where diapers were more expensive, we cannot conclude an effect on beer sales because the prices could have been higher in the past for other reasons, maybe a diaper supply shortage. The differences we see in the data are not due to the interventions we should have taken to answer the question of interest.</p>
</section>
<section id="second-rungdoing" class="level4">
<h4 class="anchored" data-anchor-id="second-rungdoing">Second rung—doing</h4>
<p>The second rung of the ladder of causation is reached when we deliberately change the world. As Pearl and MacKenzie put it</p>
<blockquote class="blockquote">
<p><em>Seeing smoke tells us a totally different story about the likelihood of fire than making smoke.</em></p>
</blockquote>
<p>Questions we answer at this level are “What if we do…?” and “What happens if …?”. The store manager now raises the price of diapers under the current market condition and observes how the sale of beer reacts to the intervention. In particular, they are interested if the conditional probability Pr(beer | diaper) changes. If the store is part of a larger chain, they can run an A/B experiment, raising the price of diapers at some randomly selected stores, and comparing the sales numbers across stores with and without price increase.</p>
</section>
<section id="third-rungimagining" class="level4">
<h4 class="anchored" data-anchor-id="third-rungimagining">Third rung—imagining</h4>
<p>The third rung of the ladder of causation answers a different set of questions, one that requires not just interventions, but theory of interventions that allows us to imagine worlds that have not happened. These “What if…?” questions are called counterfactuals. So we raised the price of diapers and beer sales dropped. Why? What caused that? Was it the change in price of diapers? Was it the cooler weather? Was it the change in the NFL schedule? To answer these questions, we need to imagine and reason about a world where we did not change the price of diapers.</p>
<p>Experiments cannot answer questions such as “What if I had done…?”; the first two rungs deal with observable phenomenon, either through observing what is or observing an intervention. The final rung of the ladder of causation requires models for the underlying processes, understanding that manifests itself in theories and what we call laws of nature.</p>
</section>
<section id="the-role-of-data" class="level4">
<h4 class="anchored" data-anchor-id="the-role-of-data">The role of data</h4>
<p>Interestingly, Pearl and MacKenzie place artificial intelligence and machine learning, as depicted by the robot, on the first rung of the ladder of causation. By simply observing what is we cannot answer causal “What if” questions at the upper rungs of the ladder: “What if I do …?”, “What if I had done …?”.</p>
<p>Does that mean we can never use observational data to make causal statements? Yes, unless the data are supplemented with models and theories that fall outside of the data. The store manager could answer the question ``What happens if I change the price of diapers?’’ without experimentation, based on a model of consumer behavior and market conditions. Combining this model with the observed data on beer—diaper sales can produce a better prediction of the effect on beer sales than the observational data alone, subject to the correctness of the assumed market model.</p>
<p>Why are we discussing all this in the context of data science?</p>
<p>Most of the data you work with is likely observational data, not experimental data. The analysis of observational data with statistical techniques is on the first rung of the ladder of causation. You cannot answer rung-2 ``What if I do..?’’ questions from this data alone; no matter the sophistication of the analytic method. In order to climb the ladder of causation and ask more interesting questions you need to collect data under manipulation or apply an external model that implies manipulation (an economic theory, for example).</p>
<p>The belief that with more data we can answer more sophisticated questions and climb the ladder of causality is fundamentally flawed. Answering more sophisticated questions from a higher rung of the ladder requires different cognitive abilities. You cannot answer questions about interventions by analyzing patterns and associations. Understanding and imagination of an autonomous driving system does not come from training on data. It comes from explicit programming—augmenting the information in the data with abilities from a higher rung of the ladder. AI systems trained on data can learn impressive tasks but are limited to tasks that can be learned by watching. They cannot learn tasks based on learning by doing. And they cannot answer counterfactual questions (“What if I had instead done …?”) without understanding and reasoning. AI derived from observational data cannot achieve intelligence.</p>
</section>
</section>
</section>
<section id="bias-variance-tradeoff" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="bias-variance-tradeoff"><span class="header-section-number">12.7</span> Bias-Variance Tradeoff</h2>
<p>The Bias-Variance tradeoff describes a fundamental tension in data science projects. The models we build are approximations because the true relationship between inputs and outputs is not known. If we work with statistical models, then the data-generating mechanism on which the model is based is also an approximation for the true—and unknown—process. The data we work with is typically the result of some selection mechanism. If we were to repeat the selection process different observations result. Apply the same method to a different set of data you will get different answers—there is variability in the results due to the inherent variability in the data.</p>
<section id="a-simulation" class="level3">
<h3 class="anchored" data-anchor-id="a-simulation">A Simulation</h3>
<p>To illustrate the concept, let’s start with a simulated example where we know the true function and collect multiple samples.</p>
<p>The following figure shows the relationship between an input variable <span class="math inline">\(X\)</span> and some output function <span class="math inline">\(f(x)\)</span>. The function depicts the true relationship, the dots mark design points at which we collect observations. Because the data is inherently variable our sample observations will not fall on the black line. If the sample is unbiased, they should spread evenly about the true trend.</p>
<div id="fig-sl-true-func" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-true-func-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_true_func.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-true-func-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.7: A response function of one input variable.
</figcaption>
</figure>
</div>
<p>Suppose that we repeat the sampling process four times, drawing eleven observations each time.</p>
<div id="fig-sl-four-draws" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-four-draws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_draws.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-four-draws-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.8: Four random samples of size eleven.
</figcaption>
</figure>
</div>
<p>This is an unrealistic situation. In real life, we do not know the solid function <span class="math inline">\(f(x)\)</span> and we draw only one set of data, for example, we would work with only the black triangles or the blue dots in the previous figure.</p>
<p>Next, we train a model on the data and are considering two types of methods: a linear regression model and a smoothing spline.</p>
<div id="fig-sl-four-reg" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-four-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_reg.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-four-reg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.9: Linear regression models fit to the four data sets.
</figcaption>
</figure>
</div>
<p>The linear regression model is not flexible. It has only two parameters, the intercept of the vertical line at <span class="math inline">\(x = 0\)</span> and the slope of the line. The lines do not follow the curved trend in the function <span class="math inline">\(f(x)\)</span>. Because of this rigidity, the four lines are somewhat similar to each other, they do not show a high degree of variability from sample to sample.</p>
<div id="fig-sl-four-splines" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-four-splines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSE_four_splines.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-four-splines-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.10: Smoothing splines with 6 degrees of freedom fit to the four data sets.
</figcaption>
</figure>
</div>
<p>The splines show more flexibility than the linear regression lines and follow the observed data more closely. The curviness of the true function <span class="math inline">\(f(x)\)</span> is echoed in the curviness of the splines, but some splines seem to try to connect the dots more than they are picking up the true trend. Because the splines follow the observed data more closely, the four functions show more variability from sample to sample than the linear regression lines.</p>
<p>Suppose the task is to develop a model that predicts a new observation well, one that did not participate in fitting the model. The model needs to generalize to previously unseen data. Should we choose linear regression or smoothing splines as our method? A method that is highly variable because it follows the data too closely will not generalize well—its predictions will be off because they are highly variable. A method that is not flexible enough also does not generalize well—its predictions will be off because the model is not correct.</p>
<p>Mathematically, we can express the problem of predicting a new observation as follows. Since the true function is unknown, it is also unknown at the new data location <span class="math inline">\(x_{0}\)</span>. However, we observed a value <span class="math inline">\(y\)</span> at <span class="math inline">\(x_{0}\)</span>. Based on the model we choose the function can be predicted at <span class="math inline">\(x_{0}\)</span>. But since we do not know the true function <span class="math inline">\(f(x)\)</span>, we can only measure the discrepancy between the value we observe and the value we predicted; this quantity is known as the error of prediction.</p>
<table class="table">
<caption>Components that contribute to bias and variance of an estimator. The last column designates whether the quantity can be measured in data science applications.</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 54%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th>Quantity</th>
<th>Meaning</th>
<th style="text-align: center;">Measurable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(f(x)\)</span></td>
<td>The true but unknown function</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="even">
<td><span class="math inline">\(f\left( x_{0} \right)\)</span></td>
<td>The value of thefunction at a data point <span class="math inline">\(x_{0}\)</span> that was not part of fitting the model</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span></td>
<td>The estimated value of the function at the new data point <span class="math inline">\(x_{0}\)</span></td>
<td style="text-align: center;">Yes</td>
</tr>
<tr class="even">
<td><span class="math inline">\(f\left( x_{0} \right) - \widehat{f}\left( x_{0} \right)\)</span></td>
<td>The function discrepancy</td>
<td style="text-align: center;">No</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(y -\widehat{f}\left( x_{0} \right)\)</span></td>
<td>The error of prediction</td>
<td style="text-align: center;">Yes</td>
</tr>
</tbody>
</table>
<p>Multiple components contribute to the prediction error: the variability of the data <span class="math inline">\(y\)</span>, the discrepancy between <span class="math inline">\(f\left( x_{0} \right)\)</span> and <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span>, and the variability of the function <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span>. The variability of <span class="math inline">\(y\)</span> is also called the <strong>irreducible variability</strong> or the <strong>irreducible error</strong> because the observations will vary according to their natural variability. Once we have decided which attribute to observe, how to sample it, and how to measure it, this variability is a given. The other two sources relate to the <strong>accuracy</strong> and <strong>precision</strong> of the prediction; or, to use statistical terms, the bias and the variance.</p>
</section>
<section id="accuracy-and-precision" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-and-precision">Accuracy and Precision</h3>
<p>In the context of measuring devices, accuracy and precision are defined as</p>
<ul>
<li><p><strong>Accuracy</strong>: How close are measurements to the true value</p></li>
<li><p><strong>Precision</strong>: How close are measurements to each other</p></li>
</ul>
<p>To demonstrate the difference between accuracy and precision, the dart board bullseye metaphor is helpful. The following figure shows four scenarios of shooting four darts each at a dart board. The goal is to hit the bullseye in the center of the board; the bullseye represents the true value we are trying to measure. <strong>A</strong> is the result of a thrower who is neither accurate nor precise. The throws vary greatly from each other (lack of precision), and the average location is far from the bullseye. <strong>B</strong> is the result of a thrower who is inaccurate but precise. The throws group tightly together (high precision) but the average location misses the bullseye (the average distance from the bullseye is not zero). The thrower with pattern <strong>C</strong> is not precise, but accurate. The throws vary widely (lack of precision) but the average distance of the darts from the bullseye is close to zero—on average the thrower hits the bullseye. Finally, the thrower in <strong>D</strong> is accurate and precise; the darts group tightly together and are centered around the bullseye.</p>
<div id="fig-sl-dartboard" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-dartboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Bullseye.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" data-glightbox="description: .lightbox-desc-4"><img src="images/Bullseye.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-dartboard-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.11: Accuracy and precision—the dart board bullseye metaphor.
</figcaption>
</figure>
</div>
<p>We see that both accuracy and precision describe not a single throw, but a pattern over many replications. In statistical terms, this long-run behavior is called an <strong>expected value</strong>.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Expected value of a random variable</p>
</div>
<div class="definition-container">
<p>The <strong>expected value</strong> of a random variable <span class="math inline">\(Y\)</span> is the <strong>mean</strong> of the random variable. It describes the long-run central tendency of <span class="math inline">\(Y\)</span> and is calculated as a weighted average of the variable’s value with their likelihood of occurrence. When the expected value is written as an operator, we use the notation <span class="math inline">\(\text{E}\lbrack Y\rbrack\)</span>. When using Greek notation, the letter <span class="math inline">\(\mu\)</span> is commonly used.</p>
<p>For a discrete random variable, one that takes on a finite number of possible values with distribution <span class="math inline">\(p(y)\)</span>, the expected value is</p>
<p><span class="math display">\[\text{E}\lbrack Y\rbrack = \sum_{y} y \, p(y)\]</span></p>
<p>For a random variable with continuous density function <span class="math inline">\(h(y)\)</span>, the expected value is</p>
<p><span class="math display">\[\text{E}\lbrack Y\rbrack = \int y\, g(y)dy\]</span></p>
</div>
</div>
<p>We used the notation <span class="math inline">\(g(y)\)</span> for the density function of the continuous random variable in this definition—rather than the notation <span class="math inline">\(f(y)\)</span> that is common in texts on statistics and probability—to avoid confusion with the function we are trying to estimate.</p>
<p>Randomness is contagious, if <span class="math inline">\(Y\)</span> is a random variable, then any function of <span class="math inline">\(Y\)</span> is a random variable as well. A special type of expected value of a function of a random variable is the <strong>variance</strong>.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Variance of a random variable</p>
</div>
<div class="definition-container">
<p>The <strong>variance</strong> of a random variable is the expected value of the squared deviation of the variable from its mean. The variance is often written as an operator, <span class="math inline">\(\text{Var}\lbrack Y\rbrack\)</span>. In Greek notation, the expression <span class="math inline">\(\sigma^{2}\)</span> is common. The variance is defined as</p>
<p><span class="math display">\[\text{Var}\lbrack Y\rbrack = \text{E}\left\lbrack \left(Y - {\text{E}\lbrack
  Y\rbrack} \right) ^2 \right\rbrack =
\text{E}\left\lbrack (Y - \mu^2) \right\rbrack\]</span></p>
<p>An alternative way to write the variance is</p>
<p><span class="math display">\[\text{Var}\lbrack Y\rbrack = \text{E}\left\lbrack Y^{2} \right\rbrack - {\text{E}\lbrack Y\rbrack}^{2}\]</span></p>
</div>
</div>
<p>While the expected value (the mean) describes the central tendency of a random variable, its typical value, if you will, the variance measures how a variable is dispersed around its mean.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Standard deviation of a random variable</p>
</div>
<div class="definition-container">
<p>The <strong>standard deviation</strong> of a random variable, often abbreviated <span class="math inline">\(\sigma\)</span>, is the square root of its variance,</p>
<p><span class="math display">\[\sigma = \sqrt{\text{Var}\lbrack Y\rbrack}\]</span></p>
</div>
</div>
<p>The standard deviation and the variance contain the same information. The standard deviation is measured in the same units as the variable <span class="math inline">\(Y\)</span>, the variance is in squared units. If <span class="math inline">\(Y\)</span> is the length of an abalone shell in cm, the variance is in areal units of cm<sup>2</sup>.</p>
<p>How do expectation and variance relate to our discussion of accuracy and precision? The accuracy of a statistical estimator is the proximity of its expected value from the target value. An estimator that is not accurate is said to be <strong>biased</strong>.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Bias</p>
</div>
<div class="definition-container">
<p>An estimator <span class="math inline">\(h\left( \text{Y} \right)\)</span> of the parameter <span class="math inline">\(\theta\)</span> is said to be biased if its expected value does not equal <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\text{Bias}\left\lbrack h\left( \textbf{Y}\right);\theta \right\rbrack = \text{E}\left\lbrack h\left( \textbf{Y}\right) - \theta \right\rbrack = \text{E}\left\lbrack h\left( \textbf{Y}\right) \right\rbrack - \theta\]</span></p>
</div>
</div>
<p>The last equality in the definition follows because the expected value of a constant is identical to the constant. In the dartboard example, <span class="math inline">\(\theta\)</span> is the bullseye and <span class="math inline">\(h\left( \text{Y} \right)\)</span> is the distance of the dart from the bullseye. The bias is the expected value of that distance, the average across many repetitions (dart throws).</p>
</section>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">Mean Squared Error</h3>
<p>With these definitions in place, let’s return to the question whether to favor the linear regression or the smoothing spline to predict a new observation at <span class="math inline">\(x_{0}\)</span>? The model can be written as</p>
<p><span class="math display">\[Y = f(x) + \epsilon\]</span></p>
<p>where <span class="math inline">\(\epsilon\)</span> is a random variable with mean 0 and variance <span class="math inline">\(\sigma^{2}\)</span>, the irreducible variability. The observational model for <span class="math inline">\(n\)</span> observed data points is</p>
<p><span class="math display">\[Y_{i} = f\left( x_{i} \right) + \epsilon_{i}\ \ \ \ \ \ \ \ \ i = 1,\ldots,n\]</span></p>
<p>The <span class="math inline">\(Y_{i}\)</span> are observed unless there are missing values. However, for a new observation this might not be the case. The model for the new observation is no different than the previous model</p>
<p><span class="math display">\[Y_{0} = f\left( x_{0} \right) + \epsilon\]</span></p>
<p>but only <span class="math inline">\(x_{0}\)</span> is known.</p>
<p>There are two possible targets for prediction: <span class="math inline">\(f\left( x_{0} \right)\)</span> and <span class="math inline">\(f\left( x_{0} \right) + \epsilon\)</span>. The former is the expected value of <span class="math inline">\(Y_{0}\)</span>: <span class="math inline">\(\text{E}\left\lbrack Y_{0} \right\rbrack = f\left( x_{0} \right) + \text{E}\lbrack\epsilon\rbrack = f\left( x_{0} \right)\)</span>. This is a fixed quantity (a constant), not a random variable. The latter is a random variable. Interestingly, the estimator of both quantities is the same, <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span>. The difference comes into play when we consider the uncertainty associated with estimating <span class="math inline">\(f\left( x_{0} \right)\)</span> or predicting <span class="math inline">\(f\left( x_{0} \right) + \epsilon\)</span>—more on this later.</p>
<p>We need a way to express the discrepancy between the estimator and the target that incorporates the estimator’s accuracy and precision—this is the mean-squared error.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Mean-squared error (MSE)</p>
</div>
<div class="definition-container">
<p>The mean-squared error of estimator <span class="math inline">\(h\left( \textbf{Y}\right)\)</span> for target <span class="math inline">\(\theta\)</span> is</p>
<p><span class="math display">\[\text{MSE}\left\lbrack h\left( \textbf{Y}\right);\ \theta \right\rbrack = \text{E}\left\lbrack \left( h\left( \textbf{Y}\right) - \theta \right)^{2} \right\rbrack\]</span></p>
<p>= <span class="math inline">\(\text{E}\left\lbrack \left( h\left( \text{Y} \right) - \text{E}\left\lbrack h\left( \textbf{Y}\right) \right\rbrack \right)^{2} \right\rbrack + \left( \text{E}\left\lbrack h\left( \textbf{Y}\right) \right\rbrack - \theta \right)^{2}\)</span></p>
<p><span class="math display">\[= \text{Var}\left\lbrack h\left( \textbf{Y}\right) \right\rbrack + \text{Bias}\left\lbrack h\left( \textbf{Y}\right);\theta \right\rbrack^{2}\]</span></p>
</div>
</div>
<p>The mean-squared error is the expected square deviation between the estimator and its target. That is akin to the definition of the variance, but the MSE is only equal to the variance if the estimator is unbiased for the target. As the last line of the definition shows, the MSE has two components, the variability of the estimator and the squared bias. The bias enters in squared terms because the variance is measured in squared units and because negative and positive bias discrepancies should not balance out.</p>
<p>If we apply the MSE definition to the problem of using estimator <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span> to predict <span class="math inline">\(f\left( x_0 \right)\)</span>,</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right)\  \right\rbrack = \text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack + \text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack^{2}\]</span></p>
<p>we see how the variability of the estimator and its squared bias contribute to the overall MSE. Similarly, if the target is to predict the new observation, rather than its mean, the expression becomes</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);Y_{0} \right\rbrack\text{ = MSE}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) + \epsilon\  \right\rbrack = \text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack + \text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack^{2} + \sigma^{2}\]</span></p>
<p>You now see why <span class="math inline">\(\sigma^{2}\)</span> is called the irreducible error. Even if the estimator <span class="math inline">\(\widehat{f}\left( x_{0} \right)\)</span> would have no variability and be unbiased, the mean-squared error in predicting <span class="math inline">\(Y_{0}\)</span> can never be smaller than <span class="math inline">\(\sigma^{2}\)</span>.</p>
<div class="example">
<div class="example-header">
<p>Example: <span class="math inline">\(k\)</span>-Nearest Neighbor Regression</p>
</div>
<div class="example-container">
<p>The <span class="math inline">\(k\)</span>-nearest neighbor (<span class="math inline">\(k\)</span>-NN for short) regression estimator is a simple estimator of the local structure between a target variable <span class="math inline">\(y\)</span> and an input variable <span class="math inline">\(x\)</span>. The value <span class="math inline">\(k\)</span> represents the number of values in the neighborhood of some target input <span class="math inline">\(x_{0}\)</span> that are used to predict <span class="math inline">\(y\)</span>. The extreme case is <span class="math inline">\(k = 1\)</span>, the value of <span class="math inline">\(f\left( x_{0} \right)\)</span> is predicted as the <span class="math inline">\(y\)</span>-value of the observation closest to <span class="math inline">\(x_{0}\)</span>.</p>
<p>Suppose our data come from a distribution with mean <span class="math inline">\(f(x)\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>. The mean-square error decomposition for the <span class="math inline">\(k\)</span>-NN estimator is then</p>
<p><span class="math display">\[\text{MSE}\left\lbrack \widehat{f}\left( x_{0} \right);Y_{0} \right\rbrack\text{ = }\frac{\sigma^{2}}{k}{+ \left\lbrack f\left( x_{0} \right) - \frac{1}{k}\sum_{}^{}Y_{(i)} \right\rbrack}^{2} + \sigma^{2}\]</span></p>
<p>where <span class="math inline">\(y_{(i)}\)</span> denotes the <span class="math inline">\(k\)</span> observations in the neighborhood of <span class="math inline">\(x_{0}\)</span>.</p>
<p>The three components of the MSE decomposition are easily identified:</p>
<ol type="1">
<li><p><span class="math inline">\(\sigma^{2}/k\)</span> is the variance of the estimator, <span class="math inline">\(\text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack\)</span>. Not surprisingly, it is the variance of the sample mean of <span class="math inline">\(k\)</span> observations drawn at random from a population with variance <span class="math inline">\(\sigma^{2}\)</span>.</p></li>
<li><p><span class="math inline">\(\left\lbrack f\left( x_{0} \right) - \frac{1}{k}\sum Y_{(i)} \right\rbrack^{2}\)</span> is the squared bias component of the MSE.</p></li>
<li><p><span class="math inline">\(\sigma^2\)</span> is the irreducible error, the variance in the population from which the data are drawn.</p></li>
</ol>
<p>While we cannot affect the irreducible error <span class="math inline">\(\sigma^{2}\)</span>, we can control the magnitude of the other components through the choice of <span class="math inline">\(k\)</span>. The variance contribution will be largest for <span class="math inline">\(k = 1\)</span>, when prediction relies on only the observation closest to <span class="math inline">\(x_{0}\)</span>. The bias contribution for this 1-NN estimator is <span class="math inline">\(\left\lbrack f\left( x_{0} \right) - Y_{(1)} \right\rbrack^{2}\)</span>.</p>
<p>As <span class="math inline">\(k\)</span> increases, the variance of the estimator decreases. For a large enough value of <span class="math inline">\(k\)</span>, all observations are included in the “neighborhood” and the estimator is equal to <span class="math inline">\(\overline{Y}\)</span>. If <span class="math inline">\(f(x)\)</span> changes with <span class="math inline">\(x\)</span>, the nearest neighbor method will then have smallest variance but large bias.</p>
</div>
</div>
<p>If we want to minimize the mean-squared error, we can strive for estimators with low bias and low variance. If we cannot have both, how do we balance between the bias and variance component of an estimator? That is the bias-variance tradeoff.</p>
<p>Statisticians resolve the tension with the UMVUE principle. Uniformly minimum-variance unbiased estimation requires to first identify unbiased estimators, those which <span class="math inline">\(\text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack = 0\)</span>, and then to select the estimator with the smallest variance among the unbiased estimators. According to UMVUE you will never consider a biased estimator. It is comforting to know that on average the estimator will be on target. This principle would select estimator <strong>C</strong> in the dartboard example over estimator <strong>B</strong> because the latter is biased. If you have only one dart left and you need to get as close to the bullseye as possible, would you ask player <strong>B</strong> or player <strong>C</strong> to take the shot for your team?</p>
<p>UMVU estimators are not necessarily minimum mean-squared error estimators. It is possible that a biased estimator has a sharply reduced variance so that the sum of variance and squared bias is smaller than the variance of the best unbiased estimator. If we want to achieve a small mean-square error, then we should consider estimators with some bias and small variance. Resolving the bias-variance tradeoff by eliminating all biased estimators does not lead to the “best” predictive models. Of course, this depends on our definition of “best”.</p>
<p>In practice, <span class="math inline">\(f\left( x_{0} \right)\)</span> is not known and the bias component <span class="math inline">\(\text{Bias}\left\lbrack \widehat{f}\left( x_{0} \right);f\left( x_{0} \right) \right\rbrack\)</span> cannot be evaluated by computing the difference of expected values. For many modeling techniques we can calculate—or at least estimate— <span class="math inline">\(\text{Var}\left\lbrack \widehat{f}\left( x_{0} \right) \right\rbrack\)</span>, the variance component of the MSE. Those derivations depend on strong assumptions about distributional properties and the correctness of the model. So, we essentially need to treat the MSE as an unknown quantity. Fortunately, we can estimate it from data.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Mean-squared prediction error (MSPE)</p>
</div>
<div class="definition-container">
<p>The mean-squared prediction error (MSPE) is the average squared prediction error in a sample of <span class="math inline">\(n\)</span> observations,</p>
<p><span class="math display">\[MSPE = \frac{1}{n}\sum_{i=1}^n\left( y_i - \widehat{f}\left( x_i \right) \right)^{2}\]</span></p>
</div>
</div>
<p>Taking the sample average replaces taking formal expectations over the distribution of <span class="math inline">\(( Y - \widehat{f}(x) )^2\)</span>.</p>
<p>Back to choosing between the regression and spline models. If we denote the two approaches <span class="math inline">\(\widehat{f}_{r}(x)\)</span> and <span class="math inline">\(\widehat{f}_{s}(x)\)</span>, respectively, selecting the winning model based on the mean-squared prediction error reduces to picking the model with the smaller MSPE:</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{f}}_{r}\left( x_{i} \right) \right)^{2}\]</span></p>
<p>or</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{f}}_{s}\left( x_{i} \right) \right)^{2}\]</span></p>
<p>As we will see, this is not without problems. These expressions are calculating the MSPE by averaging over the data points used in training the model; we call this the MSPE of the training set or MSE<sub>Tr</sub> for short. To identify models that generalize well to new observations, it is recommended to calculate the MSPE across a test set of observations that was not used to fit the model; this is called the MSPE of the test set or the MSE<sub>Te</sub> for short.</p>
<p>We will discuss training, test, and validation data sets in more detail below.</p>
<p>Whether you are working with MSPE in a regression context or MCR in a classification problem, the goal is to develop a model that is neither too complex nor too simple. We want to avoid over- and underfitting the model.</p>
</section>
<section id="overfitting-and-underfitting" class="level3">
<h3 class="anchored" data-anchor-id="overfitting-and-underfitting">Overfitting and Underfitting</h3>
<p>The preceding discussion might suggest that flexible models such as the smoothing spline have high variability and that rigid models such as the simple linear regression model have large bias. This generalization does not necessarily hold although in practice it often works out this way. The reason for this is not that simple linear regression models are biased—they can be unbiased. The reason why flexible models tend to have high variance and low bias and rigid models tend to have low variance and high bias has to do with <strong>overfitting</strong> and <strong>underfitting</strong>.</p>
<p>An overfit model follows the observed data <span class="math inline">\(Y_{i}\)</span> too closely and does not capture the mean trend <span class="math inline">\(f(x)\)</span>. The overfit model memorizes the training data too much. When you predict a new observation with an overfit model that memory causes high variability. Remember that the variability we are focusing on here is the variability across repetitions of the sample process. Imagine drawing 1,000 sets of <span class="math inline">\(n\)</span> observations, repeating the model training and predicting from each model at the new location <span class="math inline">\(x_{0}\)</span>. We now have 1,000 predictions at <span class="math inline">\(x_{0}\)</span>. Because the overfit model follows the training data too closely, its predictions will be variable at <span class="math inline">\(x_{0}\)</span>.</p>
<p>An underfit model, on the other hand, lacks the flexibility to capture the mean trend <span class="math inline">\(f(x)\)</span>. Underfit models result, for example, when important predictor variables are not included in the model.</p>
<p>The most extreme case of overfitting a model is the <strong>saturated</strong> model. It perfectly predicts the observed data. Suppose you collect only two pairs of <span class="math inline">\((x,y)\)</span> data: (1,0) and (2,1). A two-parameter straight line model will fit these data perfectly. The straight line has an intercept of –1 and a slope of +1. It passes through the observed points and the mean-squared prediction error is zero.</p>
<div id="fig-sl-saturated" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-saturated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Saturated.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-saturated-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.12: A straight line model saturates a data set with two $(x,y)$ pairs. The difference between observed values (the dots) and the predicted values (values on the line) is zero at each point. The saturated model has a MSPE of zero.
</figcaption>
</figure>
</div>
<p>Saturated models are not very interesting, they are just a re-parameterization of the data, capturing both signal <span class="math inline">\(f(x)\)</span> <strong>and</strong> noise <span class="math inline">\(\epsilon\)</span>. A useful model separates the signal from the noise. Saturated models are used behind the scenes of some statistical estimation methods, for example to measure how much of the variability in the data is captured by a model—this type of model metric is known as the deviance. Saturated models are never the end goal of data analytics.</p>
<p>On the other extreme lies the constant model; it does not use any input variables. It assumes that the mean of the target variable is the same everywhere:</p>
<p><span class="math display">\[Y_{i} = \mu + \epsilon_{i}\]</span></p>
<p>This model, also known as the intercept-only model, is slightly more useful than the saturated model. It is rarely the appropriate model in data science applications; it expresses the signal as a flat line, the least flexible model of all.</p>
<p>In our discussion of the model building process during the data science project life cycle we encountered an example of pharmacokinetic data, 500 observations on how a drug is absorbed and eliminated by the body over time (<span class="math inline">\(t\)</span>). The data are replayed in the next figure along with the fit of the constant model. The constant model underpredicts the drug concentration between times <span class="math inline">\(t = 3\)</span> and <span class="math inline">\(t = 12\)</span> and overpredicts everywhere else.</p>
<div id="fig-sl-underfit-model" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-underfit-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Underfit.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-underfit-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.13: Concentration of a drug in patient’s bodies over time.
</figcaption>
</figure>
</div>
<p>Suppose we draw 1,000 sets of <span class="math inline">\(n = 500\)</span> observations, fit the constant model to each, and predict at the new time <span class="math inline">\(t_{0}\)</span>. Because the constant model does not depend on time, we get the same predicted value regardless of the value of <span class="math inline">\(t_{0}\)</span>. In each sample of size <span class="math inline">\(n\)</span>, the predicted value will be the sample mean, <span class="math inline">\(\overline{y} = \frac{1}{500}\sum_{}^{}y_{i}\)</span>. The variability of the 1,000 predictions will be small; it is the variance of the sample mean:</p>
<p><span class="math display">\[\text{Var}\left\lbrack \widehat{f}\left( x_0 \right) \right\rbrack = \frac{\sigma^2}{500}\]</span></p>
<p>If the true model does depend on <span class="math inline">\(t\)</span>—and the plot of the data suggests this is the case—the bias of the predictions will be large. The mean-squared prediction error is dominated by the squared bias component in this case.</p>
<p>Somewhere between the two extremes of a hopelessly overfit saturated model and a hopelessly underfit constant model are models that capture the signal <span class="math inline">\(f(x)\)</span> well enough without chasing the noisy signal <span class="math inline">\(f(x) + \epsilon\)</span> too much. Those models permit a small amount of bias if that results in a reduction of the variance of the predictions.</p>
<p>To summarize,</p>
<ul>
<li><p><strong>Overfit</strong> models do not generalize well because they follow the training data too closely. They tend to have low bias and a large variance.</p></li>
<li><p><strong>Underfit</strong> models do not generalize well because they do not capture the salient trend (signal) in the data. They tend to have high bias and low variance.</p></li>
<li><p>A large mean-squared prediction error can result in either case but is due to a different cause.</p></li>
<li><p>For a small mean-squared prediction error you need to have small bias and small variance.</p></li>
<li><p>In practice, zero-bias methods with high variance are rarely the winning approaches. The best MSPE is often achieved by allowing some bias to substantially decrease the variance.</p></li>
</ul>
<p>The danger of overfitting is large when models contain many parameters, and when the number of parameters <span class="math inline">\(p\)</span> is large relative to the sample size <span class="math inline">\(n\)</span>. When many attributes (inputs) are available and you throw them all into the model, the result will likely be an overfit model that does not generalize well. It will have a large prediction error. In other words, there is a cost to adding unimportant information to a model. Methods for dealing with such high-dimensional problems play an important role in statistics and machine learning and are discussed in detail in a more advanced section. We mention here briefly:</p>
<ul>
<li><p><strong>Feature Selection</strong>: Structured approaches that use algorithms to determine which subset of the inputs should be in the model. The decision is binary in that an input is either included or excluded. Also known as variable selection.</p></li>
<li><p><strong>Regularization</strong>: Deliberately introducing some bias in the estimation through penalty terms that control the variability of the model parameters which in turn controls the variability of the predictions. The parameters are shrunk toward zero in absolute value compared to an unbiased estimator—regularization is thus also known as shrinkage estimation. The Lasso methods can shrink parameters to zero and thus combines regularization with feature selection. The Ridge regression methods also applies a shrinkage penalty but allows all inputs to contribute.</p></li>
<li><p><strong>Ensemble Methods</strong>: Ensemble methods combine multiple methods into an overall, averaged prediction or classification. Ensembles can be homogeneous, where the methods are the same, or heterogeneous. An example of a homogeneous ensemble is a bagged decision tree, where several hundred individual trees are trained independently and the predictions from the trees are averaged to obtain an overall predicted value. Due to averaging, the variance of the ensemble estimator is smaller than any individual estimator. <strong>Bagging</strong> and <strong>boosting</strong> are common ensemble methods to reduce variance.</p></li>
</ul>
</section>
</section>
<section id="training-testing-and-validation" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="training-testing-and-validation"><span class="header-section-number">12.8</span> Training, Testing, and Validation</h2>
<p>Training, testing, and validation refers to different stages of the model building process and also to different types of data used in the model building process.</p>
<section id="training-data" class="level3">
<h3 class="anchored" data-anchor-id="training-data">Training Data</h3>
<p>Training data is the set of <span class="math inline">\(n\)</span> observations used to train the model. The training data is useful to diagnose whether model assumptions are met, for example,</p>
<ul>
<li>does the model adequately describe the mean trend in the (training) data,</li>
<li>are distributional assumptions such as normality of the model errors met,</li>
<li>is it reasonable to assume that the data points are uncorrelated (or even independent)</li>
</ul>
<p>We can also use the <strong>training data</strong> after the model fit to detect data points that have a high influence of the analysis—that is, the presence of those points substantially affects an important aspect of the model. And based on the training data we can study the interdependence of the model inputs and whether those relationships affect the model performance negatively.</p>
<p>The diagnostic techniques just mentioned rely on</p>
<ul>
<li>Residual diagnostics</li>
<li>Case-deletion and influence diagnostics</li>
<li>Collinearity diagnostics</li>
</ul>
<p>These diagnostics are all very helpful, but they do not answer an important question: how well does the model generalize to observations not used in training the model; how well does the model predict new observations? We also need to figure out, given a single training data set, how to select the values for the <strong>hyperparameters</strong> of the various techniques.</p>
<div class="definition">
<div class="definition-header">
<p>Definition: Hyperparameter</p>
</div>
<div class="definition-container">
<p>A <strong>hyperparameter</strong> is a variable that controls the overall configuration of a statistical model or machine learning technique. Hyperparameters are sometimes referred to as external parameters, whereas the parameters of the model function (slopes, intercepts, etc.) are called the internal parameters.</p>
</div>
</div>
<p>Hyperparameters need to be set before a model can be trained and their values impact the performance of the model. The process of determining the values for hyperparameters given a particular data set is called <strong>hyperparameter tuning</strong>.</p>
<p>Hyperparameters include, for example,</p>
<ul>
<li>The number of terms in a polynomial model</li>
<li>The smoothing parameters in non-parametric regression models</li>
<li>The bandwidth in kernel-based estimation methods such as LOESS, kernel regression, local polynomial regression</li>
<li>The shrinkage penalty in Lasso, Ridge regression, smoothing splines</li>
<li>The depth of decision trees</li>
<li>The number <span class="math inline">\(k\)</span> in <span class="math inline">\(k\)</span>-nearest neighbor methods</li>
<li>The convergence rate and other tolerances in numerical optimization</li>
<li>The learning rate, number of nodes, and number of layers in neural networks</li>
</ul>
<p>We can calculate the MSPE or MCR of the trained model, depending on whether we are dealing with a regression or a classification problem. Doing so for the training data has some serious drawbacks. We have seen earlier that saturated models have no prediction error since they perfectly connect the dots in the data. Trying to minimize the MSPE based on the training data (MSE<sub>Tr</sub>) invariably leads to overfit models since you can always drive MSE<sub>Tr</sub> toward zero.</p>
</section>
<section id="test-data" class="level3">
<h3 class="anchored" data-anchor-id="test-data">Test Data</h3>
<p>To measure the true predictive performance of a model we need to apply the model to a different set of observations; a set that was not used in training the model. This set of observations is called the <strong>test data</strong> set. With a test data set we can measure how well the model generalizes and we can also use it to select the appropriate amount of flexibility of the model. The following graph shows the general behavior of test and train mean-squared prediction error as a function of model flexibility and complexity.</p>
<p>The MSPE of the test data set is on average higher than the MSPE of the training data set. Since these are random variables, it can happen in a particular application that the test error is lower than the training error, but this is rare. The model complexity/flexibility is measured here by the number of inputs in the model. As this number increases, the MSE<sub>Tr</sub> decreases toward zero. The MSE<sub>Te</sub>, on the other hand, first decreases, reaches a minimum, and increases again. The MSE<sub>Te</sub> is high for models with few parameters because of bias, it increases with model flexibility past the minimum because of variability. The two contributors to the MSE work at different ends of the spectrum—you find models that balance bias and variance somewhere in-between.</p>
<div id="fig-sl-train-test-error" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-train-test-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/MSETe_MSE_Tr.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-train-test-error-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.14: MSETr and MSETe as a function of model flexibility (complexity).
</figcaption>
</figure>
</div>
<p>The big question is: where do we get the test data?</p>
</section>
<section id="validation-data" class="level3">
<h3 class="anchored" data-anchor-id="validation-data">Validation Data</h3>
<p>Before discussing ways to obtain test data sets, a few words about another type of data set, the <strong>validation data</strong>. The terms test data and validation data are often used interchangeably, but there is a difference. Test data represents new data that should otherwise be representative of the training data. A test data set drawn at random from the training data set typically satisfies that.</p>
<p>Validation data can be a separate data set with known properties, for example, a benchmark data set. Such a data set can be used to compare approaches from different model families, for example, a random forest and a neural network. It can be used to measure model performance against known conditions (typical and atypical) to ensure a model works properly.</p>
<div class="example">
<div class="example-header">
<p>Example: Computer vision</p>
</div>
<div class="example-container">
<p><a href="https://www.image-net.org/">ImageNet</a> is a data set of images organized according to the WordNet hierarchy. ImageNet provides an average of 1,000 images for each meaningful concept in WordNet. The data set is used as a benchmark for object categorization algorithms and currently contains over 14 million images that are labeled and annotated by humans.</p>
<p>The most used subset of ImageNet data is the Large Scale Visual Recognition Challenge (ILSVRC) data set. It is used to evaluate object classification algorithms since 2010. The data sets for the challenges are themselves broken down into training, test, and validation sets.</p>
<p>The IARPA Janus Benchmark (IJB) datasets contain images and videos used in face detection and face recognition challenges. There are several data sets, for example IJB-B consists of 1,845 subjects with human-labeled face bounding boxes, eye &amp; nose location, and metadata such as skin tone and facial hair for 21,798 still images and 55,026 video frames. The collection methodology for the IJB-B data set is documented .</p>
</div>
</div>
<p>Test data tells us how well a model performs, validation data tells us which model is best.</p>
<div class="example">
<div class="example-header">
<p>Example: Programming competition</p>
</div>
<div class="example-container">
<p>Suppose we want to send one student from a group of students to a programming competition. The goal is to win the competition. In <strong>training</strong> the students encounter problems from past programming competitions.</p>
<p>Students that do well during training are not necessarily the best candidates for the competition. We need to find out whether a student does well because they memorized the solution or whether they truly understand how to solve the programming problem. To answer this a <strong>validation</strong> step is used and a set of new programming problems is presented, specifically designed to test student’s ability to apply general concepts in problem solving. At the end of the validation step we have identified the best student to represent the group at the competition.</p>
<p>We are not done, however. Does the best student in the group have a chance in the competition? We now enter the <strong>testing</strong> phase to answer the question: how well will the best student perform? After administering a real test with new problems, we find out that the student scores above 90%: they are ready for the competition. If, however, we find out that the student scores below 25%, we will not send them to the competition. Instead, we return to the drawing board with a new training procedure and/or a set of new training problems.</p>
</div>
</div>
<p>Validation and test data are often used interchangeably because the test data <strong>is</strong> often used as the validation data. The questions “which model is best?” and “how well does the model perform?” are answered simultaneously: the best model is the one that achieves the best metric on the test data set. Often that results in choosing the model with the lowest MSE<sub>Te</sub> or MCR<sub>Te</sub>.</p>
</section>
<section id="hold-out-sample" class="level3">
<h3 class="anchored" data-anchor-id="hold-out-sample">Hold-out Sample</h3>
<p>Let’s return to the important question: where do we find the test data set?</p>
<p>Maybe you just happen to have a separate set of data lying around that is just like the training data, but you did not use it. Well, that is highly unlikely.</p>
<p>Typically, we use the data collected, generated, or available for the study to carve out observations for training and testing. This is called a <strong>hold-out sample</strong>, a subset of the observations is held back for testing and validation. If we start with <span class="math inline">\(n\)</span> observations, we use <span class="math inline">\(n - m\)</span> observation to train the model (the training data set), and <span class="math inline">\(m\)</span> observations to test/validate the model.</p>
<p>In Python you can create this train:test split with the train_test_split() function in sklearn. The following statements load the fitness data from DuckDB into a Pandas DataFrame and split it into two frames of 15 and 16 observations.</p>
<div id="bb0a7477" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>con <span class="op">=</span> duckdb.<span class="ex">connect</span>(database<span class="op">=</span><span class="st">"../ads5064.ddb"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> con.sql(<span class="st">"SELECT * FROM fitness"</span>).df()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> train_test_split(fit,random_state<span class="op">=</span><span class="dv">235</span>,train_size<span class="op">=</span><span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>random_state=</code> parameter sets the seed for the random number generator. By setting this to a non-zero integer, the random number generator starts to produce numbers with that seed value. This makes the selection reproducible, subsequent runs of the program will produce identical—yet random—results. The <code>train_size=</code> parameter specifies the proportion of observations in the training set—if the value is between 0 and 1—or the number of observations in the training set—if the value is an integer &gt; 1.</p>
<div id="e87aac15" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>display(train.shape)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>display(train.describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(15, 7)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Weight</th>
<th data-quarto-table-cell-role="th">Oxygen</th>
<th data-quarto-table-cell-role="th">RunTime</th>
<th data-quarto-table-cell-role="th">RestPulse</th>
<th data-quarto-table-cell-role="th">RunPulse</th>
<th data-quarto-table-cell-role="th">MaxPulse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>15.000000</td>
<td>15.000000</td>
<td>15.000000</td>
<td>15.000000</td>
<td>15.000000</td>
<td>15.00000</td>
<td>15.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>49.666667</td>
<td>75.539333</td>
<td>47.693067</td>
<td>10.385333</td>
<td>52.733333</td>
<td>171.00000</td>
<td>174.133333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>4.654747</td>
<td>8.076112</td>
<td>4.516180</td>
<td>1.131408</td>
<td>7.731814</td>
<td>10.96097</td>
<td>9.210760</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>40.000000</td>
<td>59.080000</td>
<td>39.203000</td>
<td>8.170000</td>
<td>40.000000</td>
<td>148.00000</td>
<td>155.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>48.000000</td>
<td>70.760000</td>
<td>45.215500</td>
<td>9.965000</td>
<td>48.000000</td>
<td>166.00000</td>
<td>169.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>51.000000</td>
<td>76.320000</td>
<td>46.672000</td>
<td>10.330000</td>
<td>51.000000</td>
<td>170.00000</td>
<td>172.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>53.000000</td>
<td>80.400000</td>
<td>49.772000</td>
<td>11.100000</td>
<td>58.500000</td>
<td>178.00000</td>
<td>180.500000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>57.000000</td>
<td>91.630000</td>
<td>59.571000</td>
<td>12.880000</td>
<td>67.000000</td>
<td>186.00000</td>
<td>188.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="a25aac8b" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>display(test.shape)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>display(test.describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(16, 7)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Age</th>
<th data-quarto-table-cell-role="th">Weight</th>
<th data-quarto-table-cell-role="th">Oxygen</th>
<th data-quarto-table-cell-role="th">RunTime</th>
<th data-quarto-table-cell-role="th">RestPulse</th>
<th data-quarto-table-cell-role="th">RunPulse</th>
<th data-quarto-table-cell-role="th">MaxPulse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>16.000000</td>
<td>16.000000</td>
<td>16.000000</td>
<td>16.000000</td>
<td>16.000000</td>
<td>16.000000</td>
<td>16.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>45.812500</td>
<td>79.230625</td>
<td>47.078375</td>
<td>10.774375</td>
<td>54.125000</td>
<td>168.375000</td>
<td>173.437500</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>5.140931</td>
<td>8.415590</td>
<td>6.125977</td>
<td>1.605295</td>
<td>7.701731</td>
<td>9.721968</td>
<td>9.408994</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>38.000000</td>
<td>61.240000</td>
<td>37.388000</td>
<td>8.630000</td>
<td>45.000000</td>
<td>146.000000</td>
<td>155.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>43.750000</td>
<td>73.285000</td>
<td>43.665750</td>
<td>9.527500</td>
<td>48.000000</td>
<td>162.000000</td>
<td>167.500000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>44.500000</td>
<td>80.170000</td>
<td>47.023500</td>
<td>10.725000</td>
<td>53.500000</td>
<td>169.000000</td>
<td>174.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>48.500000</td>
<td>86.295000</td>
<td>50.040750</td>
<td>11.612500</td>
<td>59.000000</td>
<td>174.500000</td>
<td>180.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>57.000000</td>
<td>91.630000</td>
<td>60.055000</td>
<td>14.030000</td>
<td>70.000000</td>
<td>186.000000</td>
<td>192.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>The two data sets have very similar properties as judged by the descriptive statistics. If the goal is to develop a model that can predict the difficult to measure oxygen intake from easy to measure attributes such as age, weight, and pulse, then we would use the 15 observations in the <code>train</code> frame to fit the model and the 16 observations in the <code>test</code> frame to evaluate the model.</p>
<p>If we cull the test data from the overall data, how should we determine an appropriate size for the test data? The previous example used a 50:50 split, would it have mattered if we had taken a 20:80 or a 90:10 split? For the two data sets to serve their respective functions, you need enough observations in the training data set to fit the model well enough so it can be tested, and you need enough observations in the test data set to produce a stable estimate of MSE<sub>Te</sub>. In practice splits that allocate between 50 and 90% of the observations to the training data set are common.</p>
<p>With small training proportions you run the risk that the model cannot be fit and/or that the data does not support the intended model. For example, with a 10:90 train:test split in the fitness example, the training data contains only 3 observations and evaluating the effect of all input variables on oxygen intake is not possible—the model is saturated after three inputs are in the model. With categorical inputs, you need to make sure that the training and test data sets contain all the categories. For example, if you categorize age into four age groups and only three groups are present in the training data after the split, the resulting model no longer applies to a population with four age groups.</p>
<p>From this discussion we can glean the general advantages and disadvantages of hold-out test samples.</p>
<table class="table-striped table">
<caption>Advantages and disadvantages of hold-out samples generated by random train:test splits.</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Easy to do</td>
<td>Involves a random selection; results change depending on which observations selected</td>
</tr>
<tr class="even">
<td>No separate test data set needed</td>
<td>Potentially large variability from run to run, especially for noisy data</td>
</tr>
<tr class="odd">
<td>A general method that can be applied regardless of how model performance is measured</td>
<td>Must decide how large to make the training (test) set</td>
</tr>
<tr class="even">
<td>Reproducible if fixing random number seed</td>
<td>An observation is used either for testing or for training</td>
</tr>
<tr class="odd">
<td></td>
<td>Tends to overestimate the test error compared to cross-validation methods</td>
</tr>
</tbody>
</table>
<p>The last two disadvantages in the table weigh heavily. Since we cannot rely on the training error for model selection, we are <em>sacrificing</em> observations by excluding them from training. At least we expect then a good estimate of the test error. The reason for overestimating the true test error with a train:test hold-out sample is that models tend to perform worse when trained on fewer observations. Reducing the size of the training data set results in less precise parameter estimates which in turn increases the variability of predictions.</p>
<p>To compare the variability of the hold-out sample method with other techniques, we draw on the Auto data set from ISLR2 (An Introduction to Statistical Learning by James et al.). The data comprise information on fuel mileage and other vehicle attributes of 392 automobiles. Suppose we want to model mileage as a function of horsepower. The next figure shows the raw data and fits of a linear and quadratic model</p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_{1}\text{horsepower}_{i} + \epsilon_{i}\]</span></p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_{1}\text{horsepower}_{i} + {\beta_{2}\text{horsepower}_{i}^{2} + \epsilon}_{i}\]</span></p>
<div id="fig-sl-auto-linquad" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-auto-linquad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_lin_quad.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-auto-linquad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.15: Simple linear and quadratic polynomial fit for miles per gallon versus horsepower in Auto data set.
</figcaption>
</figure>
</div>
<p>A simple linear regression—the red line in the figure—does not seem appropriate. The model does not pick up the curvature in the underlying trend. A quadratic model seems more appropriate. Can this be quantified? What about a cubic model</p>
<p><span class="math display">\[\text{mpg}_{i} = \beta_{0} + \beta_1\text{horsepower}_i + \beta_2\text{horsepower}_i^2 + \beta_3\text{horsepower}_i^3 + \epsilon_{i}\]</span></p>
<p><a href="#fig-sl-auto-loocv" class="quarto-xref">Figure&nbsp;<span>12.16</span></a> shows the hold-out test errors for all polynomial models up to degree 10. The simple linear regression (SLR) model has degree 1 and is shown on the left. The test error is large for the SLR model and for the 10-degree polynomial. The former is biased as can be seen from the previous graph. The latter is too wiggly and leads to a poor test error because of high variability. The test error is minimized for the quadratic model but we note that the test error is also low for degrees 7—9.</p>
<div id="fig-sl-auto-loocv" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-auto-loocv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_Valid1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-auto-loocv-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.16: Hold-out test errors for polynomial models from first to tenth degree. The horizontal line marks the minimum, achieved at degree 2.
</figcaption>
</figure>
</div>
<p>Based on this result we would probably choose the second-degree polynomial. To what extent is this decision the result of having selected the specific 196 observations in the 50:50 split? We can evaluate this by repeating the sampling process a few more times. The next graph shows the results of 9 additional 50:50 random splits.</p>
<p>The variability in the results is considerable. Most replications would select a second-degree polynomial as the model with the lowest MSE<sub>Te</sub>, but several replications achieve a smallest MSE<sub>Te</sub> for much higher degree polynomials (5<sup>th</sup> degree, 7<sup>th</sup> degree, etc.).</p>
<div id="fig-sl-auto-valid10" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-auto-valid10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_valid10.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-auto-valid10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.17: Test errors in ten hold-out samples, 50:50 splits. The errors from the previous graph are shown in red.
</figcaption>
</figure>
</div>
<p>Having spent time, energy, resources, money to build a great data set, it seems wasteful to use some observations only for training and the others only for testing. Is there a way in which we can use all observation for training and testing and still get a good estimate (maybe even a better estimate) of the test error?</p>
<p>How about the following proposal:</p>
<ul>
<li><p>Split the data 50:50 into sets <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span></p></li>
<li><p>Use <span class="math inline">\(t_1\)</span> as the training data set and determine the mean-squared prediction error from <span class="math inline">\(t_{2}\)</span>, call this MSE<sub>Te</sub>(<span class="math inline">\(t_{2}\)</span>)</p></li>
<li><p>Reverse the roles of <span class="math inline">\(t_1\)</span> and <span class="math inline">\(t_2\)</span>, using <span class="math inline">\(t_2\)</span> to train the model and <span class="math inline">\(t_1\)</span> to compute the test error MSE<sub>Te</sub>(<span class="math inline">\(t_1\)</span>)</p></li>
<li><p>Compute the overall test error as the average MSE<sub>Te</sub> = 0.5 x (MSE<sub>Te</sub>(<span class="math inline">\(t_1\)</span>) + MSE<sub>Te</sub>(<span class="math inline">\(t_2\)</span>))</p></li>
</ul>
<p>Each observation is used once for training and once for testing. Because of averaging, the combined estimate of test error is more reliable than the individual test errors.</p>
<p>This proposal describes a special case of <strong>cross-validation</strong>, namely 2-fold cross-validation.</p>
</section>
</section>
<section id="cross-validation" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="cross-validation"><span class="header-section-number">12.9</span> Cross-validation</h2>
<p>Cross-validation is a general method to measure the performance of a model. It is commonly used for predictive models to evaluate how well a model generalizes to new observations, but it can also be used to, for example, select hyperparameters. Cross-validation extends the concept of the hold-out sample to address the drawbacks of train:test splits. It is also general in that you are not limited to MSE or MCR as performance measurements. So, first, a few words about loss functions.</p>
<section id="loss-functions" class="level3">
<h3 class="anchored" data-anchor-id="loss-functions">Loss Functions</h3>
<div class="definition">
<div class="definition-header">
<p>Definition: Loss function</p>
</div>
<div class="definition-container">
<p>A <strong>loss function</strong> or <strong>cost function</strong> maps an event to a real number that reflects some loss or cost incurred from the event.</p>
<p>In data analytics, loss functions measure the discrepancy between observed and predicted values and the losses are typically referred to as <em>errors</em>.</p>
</div>
</div>
<p><a href="#tbl-loss-functions" class="quarto-xref">Table&nbsp;<span>12.2</span></a> displays common loss functions in data science.</p>
<div id="tbl-loss-functions" class="striped quarto-float anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-loss-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;12.2: Loss functions common in data science applications. <span class="math inline">\(y\)</span> and <span class="math inline">\(\widehat{y}\)</span> denote observed and predicted value, respectively. <span class="math inline">\(\widehat{p}_j\)</span> denotes the sample proportion in category <span class="math inline">\(j\)</span> of a classification problem with <span class="math inline">\(k\)</span> categories.
</figcaption>
<div aria-describedby="tbl-loss-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table">
<colgroup>
<col style="width: 18%">
<col style="width: 51%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Loss Function</th>
<th style="text-align: center;">Expression</th>
<th>Application Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Squared Error</td>
<td style="text-align: center;"><span class="math inline">\(\left( y - \widehat{y} \right)^{2}\)</span></td>
<td>Regression with continuous response</td>
</tr>
<tr class="even">
<td>Zero-one (0—1)</td>
<td style="text-align: center;"><span class="math inline">\(I\left( y \neq \widehat{y} \right)\)</span></td>
<td>Classification</td>
</tr>
<tr class="odd">
<td>Absolute Value</td>
<td style="text-align: center;"><span class="math inline">\(\left| y - \widehat{y} \right|\)</span></td>
<td>Robust regression</td>
</tr>
<tr class="even">
<td>Misclassification</td>
<td style="text-align: center;"><span class="math inline">\(1 - \max_{j}{\widehat{p}}_{j}\)</span></td>
<td>Pruning of decision trees</td>
</tr>
<tr class="odd">
<td>Gini Index</td>
<td style="text-align: center;"><span class="math inline">\(\sum_{j = 1}^{k}{{\widehat{p}}_{j}\left( 1 - {\widehat{p}}_{j} \right)}\)</span></td>
<td>Growing of decision trees, neural networks</td>
</tr>
<tr class="even">
<td>Cross-entropy (deviance)</td>
<td style="text-align: center;"><span class="math inline">\(- 2\sum_{j = 1}^{k}{{n_{j}\log}{\widehat{p}}_{j}}\)</span></td>
<td>Growing of decision trees, neural networks</td>
</tr>
<tr class="odd">
<td>Entropy</td>
<td style="text-align: center;"><span class="math inline">\(- \sum_{j = 1}^{k}{{\widehat{p}}_{j}\log{\widehat{p}}_{j}}\)</span></td>
<td>Growing of decision trees</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Squared error and zero-one loss dominate data science work in regression and classification problems. For specific methods you will find additional loss functions used to optimize a particular aspect of the model, for example, growing and pruning of decision trees.</p>
<p>Suppose the loss associated with an observation is denoted <span class="math inline">\(\mathcal{l}_{i}\)</span>. Cross-validation estimates the average loss for each of <span class="math inline">\(k\)</span> sets of observations and averages the <span class="math inline">\(k\)</span> estimates into an overall cross-validation estimate of the loss.</p>
<p>Suppose we create two random sets of (near) equal size for the 31 observations in the fitness data set; <span class="math inline">\(k = 2\)</span>. The sets will have <span class="math inline">\(n_{1} = 15\)</span> and <span class="math inline">\(n_{2} = 16\)</span> observations. This leads to one cross-validation estimate of the loss function for each set:</p>
<p><span class="math display">\[{CV}_{1}\left( \mathcal{l} \right) = \frac{1}{n_{1}}\sum_{i = 1}^{n_{1}}\mathcal{l}_{i}\]</span></p>
<p><span class="math display">\[{CV}_{2}\left( \mathcal{l} \right) = \frac{1}{n_{2}}\sum_{i = 1}^{n_{1}}\mathcal{l}_{i}\]</span></p>
<p>The overall cross-validation loss is the average of the two:</p>
<p><span class="math display">\[CV\left( \mathcal{l} \right) = \frac{1}{2}\left( {CV}_{1}\left( \mathcal{l} \right) + {CV}_{2}\left( \mathcal{l} \right) \right)\]</span></p>
<p>This is a special case of <span class="math inline">\(k\)</span>-fold cross-validation; the sets are referred to as folds. The other special case is leave-one-out cross-validation.</p>
</section>
<section id="k-fold-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="k-fold-cross-validation"><span class="math inline">\(K\)</span>-fold Cross-validation</h3>
<p>The set of <span class="math inline">\(n\)</span> observations is divided randomly into <span class="math inline">\(k\)</span> groups of (approximately) equal size. The groups are called the <span class="math inline">\(k\)</span> folds. The model is fit <span class="math inline">\(k\)</span> times, holding out a different fold each time. After computing the loss in each fold</p>
<p><span class="math display">\[{CV}_{j}\left( \mathcal{l} \right) = \frac{1}{n_{j}}\sum_{i = 1}^{n_{j}}\mathcal{l}_{i}\]</span></p>
<p>the overall loss is calculated as the average</p>
<p><span class="math display">\[CV\left( \mathcal{l} \right) = \frac{1}{k}\sum_{j = 1}^{k}{{CV}_{j}\left( \mathcal{l} \right)}\]</span></p>
<p>The following figure shows 5-fold cross-validation for <span class="math inline">\(n = 100\)</span> observations. The observations are randomly divided into 5 groups of 20 observations each. The model is trained five times. The first time around, observations in fold 1 serve as the test data set, folds 2—5 serve as the training data set. The second time around, fold 2 serves as the test data set and folds 1, 3, 4, and 5 are the training data set; and so forth. Each time, the average loss is calculated for the 20 observations not included in training. At the end, five average cross-validation losses are averaged to calculate the overall loss.</p>
<div id="fig-sl-cv-folds" class="lightbox quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-cv-folds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/five_fold_CV.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" data-glightbox="description: .lightbox-desc-5"><img src="images/five_fold_CV.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-cv-folds-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.18: Example of 5-fold cross-validation for 100 observations. Numbers in the cells represent observation numbers. The records were randomly arranged prior to assigning the folds.
</figcaption>
</figure>
</div>
<table class="table-striped table">
<caption>Advantages and disadvantages of <span class="math inline">\(k\)</span>-fold cross-validation.</caption>
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantgages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Not as variable as the train:test hold-out sample</td>
<td>Still has a random element due to randomly splitting the data into <span class="math inline">\(k\)</span> sets</td>
</tr>
<tr class="even">
<td>Less bias in test error than train:test hold-out sample</td>
<td>Can becomputationally intensive if the model must be fit <span class="math inline">\(k\)</span> times</td>
</tr>
<tr class="odd">
<td>Not as computationally intensive as leave-one-out cross-validation (see below)</td>
<td>Must decide on the number of folds</td>
</tr>
<tr class="even">
<td>Every observation is used for training (<span class="math inline">\(k - 1\)</span> times) and testing (once)</td>
<td></td>
</tr>
<tr class="odd">
<td>Reproducible if fixing random number seed</td>
<td></td>
</tr>
<tr class="even">
<td>A general method that can be applied regardless of how model performance is measured</td>
<td></td>
</tr>
</tbody>
</table>
<p>The most common values for <span class="math inline">\(k\)</span> found in practice are 5, 10, and <span class="math inline">\(n\)</span>. <span class="math inline">\(k = n\)</span> is a special case, called leave-one-out cross-validation; see below. Values of 5 and 10 have shown to lead to good estimates of loss while limiting the variability of the results. The averaging of the losses from the folds has a powerful effect of stabilizing the results.</p>
<p>For the Auto data set, the following figures show the results of repeating 5-fold and 10-fold cross-validation ten times. The results vary considerably less than the ten repetitions of the 50:50 hold-out sample in the previous section.</p>
<div id="fig-sl-auto-cv5sim" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-auto-cv5sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_5fold_sim.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-auto-cv5sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.19: Ten repetitions of 5-fold cross-validation for polynomials of degree 1—10; Auto data set.
</figcaption>
</figure>
</div>
<div id="fig-sl-auto-cv10sim" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sl-auto-cv10sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/Auto_10fold_sim.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sl-auto-cv10sim-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12.20: Ten repetitions of 10-fold cross-validation for polynomials of degree 1—10; Auto data set.
</figcaption>
</figure>
</div>
<p>The results of 10-fold cross-validation vary less than those of 5-fold CV. This is the effect of averaging 10 quantities rather than 5. The effect of averaging the results from the folds is stronger than the averaging of observations within the folds. But if training a model is computationally intensive, 5-fold cross-validation is a good solution.</p>
</section>
<section id="leave-one-out-cross-validation" class="level3">
<h3 class="anchored" data-anchor-id="leave-one-out-cross-validation">Leave-One-Out Cross-validation</h3>
<p>Abbreviated LOOCV, this method takes the random element out of selecting observations into the folds. Instead, each observation is used once as a test set of size 1 and the model is fit to the remaining <span class="math inline">\(n - 1\)</span> observations. The observation is put back and the next observation is removed from the training set.</p>
<p>LOOCV thus estimates the model <span class="math inline">\(n\)</span> times, each time removing one of the observations. It is a special case of <span class="math inline">\(k\)</span>-fold cross-validation where <span class="math inline">\(k = n\)</span>.</p>
<p>A pseudo-algorithm for LOOCV is as follows:</p>
<p>Step 0: Set <span class="math inline">\(i = 1\)</span></p>
<p>Step 1: Set the index of the hold-out observation to <span class="math inline">\(i\)</span></p>
<p>Step 2. Remove observation <span class="math inline">\(i\)</span> and fit the model to the remaining <span class="math inline">\(n - 1\)</span> observations</p>
<p>Step 3. Compute the loss <span class="math inline">\(\mathcal{l}_{i}\)</span> for the held-out observation</p>
<p>Step 4. Put the observation back into the data. If <span class="math inline">\(i = n\)</span>, go to Step 5. Otherwise, increment <span class="math inline">\(i\)</span> and return to Step 1.</p>
<p>Step 5. Compute the LOOCV loss as the average of the <span class="math inline">\(n\)</span> losses: <span class="math inline">\(CV\left( \mathcal{l} \right) = \frac{1}{n}\sum_{i}^{}\mathcal{l}_{i}\)</span></p>
<table class="table-striped table">
<caption>Advantages and disadvantage of leave-one-out cross-validation.</caption>
<colgroup>
<col style="width: 28%">
<col style="width: 71%">
</colgroup>
<thead>
<tr class="header">
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No randomness involved. Identical results upon repetition.</td>
<td>Can become computationally intensive if fitting a model is expensive and no closed-form expressions (or approximations) are available to compute the loss per observation based on a single fit</td>
</tr>
<tr class="even">
<td>Every observation is used in training (<span class="math inline">\(n - 1\)</span> times) and in testing (once)</td>
<td></td>
</tr>
<tr class="odd">
<td>A general method that can be applied to any loss function and model</td>
<td></td>
</tr>
<tr class="even">
<td>Good estimate of test error</td>
<td></td>
</tr>
</tbody>
</table>
<p>The results of LOOCV for the Auto data set are shown in <a href="#fig-sl-auto-loocv" class="quarto-xref">Figure&nbsp;<span>12.16</span></a>. LOOCV selects the seventh-degree polynomial.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Auto_Loocv.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Leave-one-out cross-validation for polynomials in the Auto data set.</figcaption>
</figure>
</div>
<p>Fortunately, the leave-one-out cross-validation error can be computed for some model classes without fitting the model <span class="math inline">\(n\)</span> times. For linear regression models, formulas exist to compute the LOO prediction error from information available after just training the model once on all observations. Wait, what?</p>
<p>Suppose we are predicting the target value of the <span class="math inline">\(i\)</span><sup>th</sup> observation in the LOO step when that observation is not in the training set and denote this predicted value as <span class="math inline">\(\widehat{y}_{-i}\)</span>. The LOO cross-validation error using a squared error loss function is then</p>
<p><span class="math display">\[\frac{1}{n}\sum_{i = 1}^{n}\left( y_{i} - {\widehat{y}}_{- i} \right)^{2}\]</span></p>
<p>The sum in this expression is called the PRESS statistic (for <strong>pre</strong>diction <strong>s</strong>um of <strong>s</strong>quares). The interesting result is that<span class="math inline">\({\widehat{\ y}}_{- i}\)</span> can be calculated as</p>
<p><span class="math display">\[y_{i} - \widehat{y}_{- i} = \frac{y_i - \widehat{y}_i}{1 - h_{ii}}\]</span></p>
<p>where <span class="math inline">\(h_{ii}\)</span> is called the <strong>leverage</strong> of the <span class="math inline">\(i\)</span><sup>th</sup> observation. We will discuss the leverage in more detail in the context of linear model diagnostics. At this point it is sufficient to note that the leverage measures how unusual an observation is with respect to the input variables of the model and that <span class="math inline">\(0 &lt; h_{ii} &lt; 1\)</span>.</p>
<p>The term in the numerator is the regular residual for <span class="math inline">\(y_{i}\)</span>. In other words, we can calculate the leave-one-out prediction error from the difference between observed and predicted values in the full training data by adjusting for the leverage. Since <span class="math inline">\(0 &lt; h_{ii} &lt; 1\)</span>, it follows that</p>
<p><span class="math display">\[y_{i} - \widehat{y}_{- i} &gt; y_{i} - \widehat{y}_i\]</span></p>
<p>Predicting an observation that was not used in training the model cannot be more precise than predicting the observation if it is part of the training set.</p>


<div class="hidden" aria-hidden="true">
<span class="glightbox-desc lightbox-desc-1">Figure&nbsp;12.1: Mitscherlich yield equation for plant yield as a function of nitrogen rate fitted to a set of data.</span>
<span class="glightbox-desc lightbox-desc-2">Figure&nbsp;12.3: An example of regression to the mean. An extreme observation is more likely to be followed by a less extreme observation, one that falls near the center of the distribution.</span>
<span class="glightbox-desc lightbox-desc-3">Figure&nbsp;12.6: The Ladder of Causation according to Pearl and MacKenzie.</span>
<span class="glightbox-desc lightbox-desc-4">Figure&nbsp;12.11: Accuracy and precision—the dart board bullseye metaphor.</span>
<span class="glightbox-desc lightbox-desc-5">Figure&nbsp;12.18: Example of 5-fold cross-validation for 100 observations. Numbers in the cells represent observation numbers. The records were randomly arranged prior to assigning the folds.</span>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../data/integration.html" class="pagination-link" aria-label="Data Integration">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Data Integration</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../statlearning/mathstat.html" class="pagination-link" aria-label="Probability and Statistics">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Probability and Statistics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Foundations of Data Science by Oliver Schabenberger</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This book was built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"zoom","descPosition":"bottom","selector":".lightbox","closeEffect":"zoom","loop":false});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>